{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# cross-correlation\n",
    "def corr2d(X,K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros(X.shape[0] - h + 1,X.shape[1]-w+1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+h,j:j+w]*K).sum()\n",
    "    return Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# conv_layer\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight)+ self.bias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# detect\n",
    "X = torch.ones((8,8))\n",
    "X[2:6,2:6] = 0\n",
    "\n",
    "K = torch.tensor([[1.0,-1.0]]) # conv kernel h = 1; w = 2\n",
    "# 接下来，我们构造一个高度为 1 、宽度为 2 的卷积核K。\n",
    "# 当进行互相关运算时，如果水平相邻的两元素相同，则输出为零，\n",
    "# 否则输出为非零。\n",
    "Y = corr2d(X,K)\n",
    "Y2 = corr2d(X.t(),K).t()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_18838/3785505991.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# learn to creat a kernel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# initiate a conv kernel with random elements\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mconv2d\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mConv2d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mkernel_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv2d\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# set batch number:1 and channel:1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# learn to creat a kernel\n",
    "# initiate a conv kernel with random elements\n",
    "conv2d = nn.Conv2d(1,1,kernel_size=(1,2),bias=False)\n",
    "print(conv2d.weight.data)\n",
    "X = X.reshape(1,1,8,8) # set batch number:1 and channel:1\n",
    "Y = Y.reshape(1,1,8,7)\n",
    "lr = 1e-2\n",
    "\n",
    "for i in range(101):\n",
    "    Y_hat = conv2d(X) #kernel size: 1 x 1 x 1 x 2\n",
    "    l = (Y_hat-Y)**2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    conv2d.weight.data[:] -= lr*conv2d.weight.grad\n",
    "    if i % 10 == 0:\n",
    "        print(f'epoch {i+1}:loss:{l.sum()}')\n",
    "        print(conv2d.weight.data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 4])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding and stride\n",
    "\n",
    "# padding\n",
    "def comp_conv2d(conv2d,X):\n",
    "    X = X.reshape((1,1)+X.shape) # connect tow tuples\n",
    "    Y = conv2d(X)\n",
    "    return Y.reshape(Y.shape[2:]) # only need height and width\n",
    " # add an element in each side of every cow and every column\n",
    " # as conv will decrease elements in input matrix\n",
    "conv2d = nn.Conv2d(1,1,kernel_size=3,padding=(1,1))\n",
    "X = torch.rand(size=(8,8))\n",
    "comp_conv2d(conv2d,X).shape\n",
    "# stride\n",
    "conv2d = nn.Conv2d(1,1,kernel_size=3,padding=(1,1),stride=(2,2)) # total padding:2 stride = 2\n",
    "# if input: width: 8 -> output: width: (8-3+1+2)/2+1 = 4 same to the height\n",
    "X = torch.rand(size = (8,8))\n",
    "comp_conv2d(conv2d,X).shape #out: torch,size([4,4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "#multiple input channel\n",
    "def corr2d_mult_in(X,K):\n",
    "    \"\"\"X has multiple input channel (shape:c,h,w) also is K\"\"\"\n",
    "    return sum([corr2d(x,k) for x,k in zip(X,K)])\n",
    "X = torch.randn(size=(2,8,8))\n",
    "# k = nn.Conv2d(kernel_size=(3,3),in_channels=2,out_channels=1)\n",
    "k = torch.randn(size=(2,3,3)) # kernel\n",
    "corr2d_mult_in(X,k)\n",
    "\n",
    "#multiple output channel\n",
    "def corr2d_mult_in_out(X,K):\n",
    "    \"\"\"the dim of K should be 4 to let output has multiple channel\"\"\"\n",
    "    return torch.stack([corr2d_mult_in(X,k)for k in K],0) # stack in dim 0\n",
    "# get a 4 dim K\n",
    "K = torch.stack([k,k+1,k+2],0) # 3*2*3*3\n",
    "K.shape\n",
    "corr2d_mult_in_out(X,K)\n",
    "\n",
    "# 1x1 kernel: use to calculate value on a point with multiple input channel (like sum())\n",
    "# as same as full connection layer\n",
    "def corr2d_multi_in_out_1x1(X,K):\n",
    "    channel_i,w,h = X.shape\n",
    "    channel_o = k.shape[0]\n",
    "    X = X.reshape((channel_i,h*w))\n",
    "    K = K.reshape((channel_o,channel_i))\n",
    "    Y = torch.matmul(K,X)\n",
    "    return Y.reshape((channel_o,w,h)) # 1x1 would not change w and h only changes channels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 1., 2.],\n",
      "          [3., 4., 5.],\n",
      "          [6., 7., 8.]],\n",
      "\n",
      "         [[1., 2., 3.],\n",
      "          [4., 5., 6.],\n",
      "          [7., 8., 9.]]]])\n",
      "tensor([[[[4., 5., 5.],\n",
      "          [7., 8., 8.],\n",
      "          [7., 8., 8.]],\n",
      "\n",
      "         [[5., 6., 6.],\n",
      "          [8., 9., 9.],\n",
      "          [8., 9., 9.]]]])\n"
     ]
    }
   ],
   "source": [
    "# pooling layer\n",
    "# 降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性。\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# maximum pooling layer\n",
    "# output the maximum value in an input region\n",
    "# average pooling layer\n",
    "# output the average value in an input regin\n",
    "# so that a little change in position of pixel would not affect the final output\n",
    "# like the corr calculation, the pool layer also has something like stride and padding?(may be not)\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h,p_w = pool_size\n",
    "    Y = torch.zeros(X.shape[0] - p_h+1,X.shape[1] - p_w + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i,j] = X[i:i+p_h,j:j+p_w].max()\n",
    "            elif mode=='avg':\n",
    "                Y[i,j] = X[i:i+p_h,j:j+p_w].mean()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "PX = pool2d(X, (2, 2))\n",
    "# print(X)\n",
    "# print(PX)\n",
    "\n",
    "# use pool layer in torch\n",
    "pool2d_max_torch = nn.MaxPool2d((3,3))\n",
    "pool2d_max_torch(X.reshape((1,1,3,3))) # attention the shape of input\n",
    "# add padding and stride to pool layer\n",
    "pool2d_max_torch = nn.MaxPool2d(kernel_size=(3,3),padding=1,stride=1)\n",
    "pool2d_max_torch(X.reshape((1,1,3,3))) # attention the shape of input\n",
    "\n",
    "pool2d_max_torch = nn.MaxPool2d(kernel_size=(3,3),padding=1,stride=2)\n",
    "pool2d_max_torch(X.reshape((1,1,3,3))) # attention the shape of input\n",
    "\n",
    "# not same to the conv kernel, input can also have multiple channel but the calculation would affect same channel, in other word, output channel would be same to the input channel\n",
    "# multiple input channel\n",
    "X = X.reshape((1,1,3,3)) # batch size: 1, channel: 1, height: 3, wight: 3\n",
    "X = torch.cat((X,X+1),1) # construct multiple channel\n",
    "pool2d_max_torch = nn.MaxPool2d(kernel_size=(3,3), padding=1, stride=1)\n",
    "print(X)\n",
    "print(pool2d_max_torch(X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t\t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t\t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t\t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t\t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t\t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t\t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t\t torch.Size([1, 400])\n",
      "Linear output shape: \t\t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t\t torch.Size([1, 120])\n",
      "Linear output shape: \t\t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t\t torch.Size([1, 84])\n",
      "Linear output shape: \t\t torch.Size([1, 10])\n",
      "net will be trained on cuda:0\n",
      "batch_0: train_l:2.439532995223999, train_accuracy:0.12890625, time_count:0.2802743911743164\n",
      "batch_10: train_l:2.5029625459150835, train_accuracy:0.10014204545454546, time_count:0.004795074462890625\n",
      "batch_20: train_l:2.4219164167131697, train_accuracy:0.09691220238095238, time_count:0.004835844039916992\n",
      "batch_30: train_l:2.3912743137728785, train_accuracy:0.09954637096774194, time_count:0.004835605621337891\n",
      "batch_40: train_l:2.3722413632927872, train_accuracy:0.10080030487804878, time_count:0.0048215389251708984\n",
      "batch_50: train_l:2.3598176731782803, train_accuracy:0.1016390931372549, time_count:0.004611492156982422\n",
      "batch_60: train_l:2.353057181248899, train_accuracy:0.10053790983606557, time_count:0.004762411117553711\n",
      "batch_70: train_l:2.3479201592190164, train_accuracy:0.09881161971830986, time_count:0.004758596420288086\n",
      "batch_80: train_l:2.3437785631344643, train_accuracy:0.09900655864197531, time_count:0.004302024841308594\n",
      "batch_90: train_l:2.340012306695456, train_accuracy:0.09847184065934066, time_count:0.004078865051269531\n",
      "batch_100: train_l:2.3367278457868217, train_accuracy:0.10009282178217822, time_count:0.0043103694915771484\n",
      "batch_110: train_l:2.3343262758340924, train_accuracy:0.0995213963963964, time_count:0.004152059555053711\n",
      "batch_120: train_l:2.3322288852092647, train_accuracy:0.09923811983471074, time_count:0.004911184310913086\n",
      "batch_130: train_l:2.33048524747368, train_accuracy:0.09977337786259542, time_count:0.004385471343994141\n",
      "batch_140: train_l:2.3288177767543927, train_accuracy:0.09940159574468085, time_count:0.004953145980834961\n",
      "batch_150: train_l:2.3272391707691926, train_accuracy:0.0994153559602649, time_count:0.0045740604400634766\n",
      "batch_160: train_l:2.325779272162396, train_accuracy:0.10003396739130435, time_count:0.0047032833099365234\n",
      "batch_170: train_l:2.324491113250019, train_accuracy:0.10016904239766082, time_count:0.00472712516784668\n",
      "batch_180: train_l:2.323256667806299, train_accuracy:0.09955542127071823, time_count:0.004431247711181641\n",
      "batch_190: train_l:2.3219416228888545, train_accuracy:0.10021269633507854, time_count:0.004248142242431641\n",
      "batch_200: train_l:2.3206114804566798, train_accuracy:0.10088230721393035, time_count:0.004968404769897461\n",
      "batch_210: train_l:2.3189343219684764, train_accuracy:0.10341380331753554, time_count:0.0046575069427490234\n",
      "batch_220: train_l:2.316552052131066, train_accuracy:0.10486778846153846, time_count:0.0037419795989990234\n",
      "batch_230: train_l:2.3121157910400654, train_accuracy:0.10820819805194805, time_count:0.003724336624145508\n",
      "================================\n",
      "epoch_0: test_acc:0.3073\n",
      "================================\n",
      "batch_0: train_l:2.121392011642456, train_accuracy:0.29296875, time_count:0.00690913200378418\n",
      "batch_10: train_l:2.0659153136340054, train_accuracy:0.24964488636363635, time_count:0.004960298538208008\n",
      "batch_20: train_l:1.9453623805727278, train_accuracy:0.27920386904761907, time_count:0.004454374313354492\n",
      "batch_30: train_l:1.823376513296558, train_accuracy:0.3112399193548387, time_count:0.003989458084106445\n",
      "batch_40: train_l:1.7500474074991739, train_accuracy:0.3327934451219512, time_count:0.0046977996826171875\n",
      "batch_50: train_l:1.692370145928626, train_accuracy:0.35071997549019607, time_count:0.00455927848815918\n",
      "batch_60: train_l:1.6338904255726299, train_accuracy:0.37051741803278687, time_count:0.004626035690307617\n",
      "batch_70: train_l:1.5799972389785337, train_accuracy:0.387268926056338, time_count:0.004224061965942383\n",
      "batch_80: train_l:1.5341351665096519, train_accuracy:0.4021026234567901, time_count:0.004370450973510742\n",
      "batch_90: train_l:1.4912543205114512, train_accuracy:0.41856971153846156, time_count:0.003968000411987305\n",
      "batch_100: train_l:1.4618188732921487, train_accuracy:0.42670946782178215, time_count:0.004606008529663086\n",
      "batch_110: train_l:1.431734043198663, train_accuracy:0.43665540540540543, time_count:0.0043904781341552734\n",
      "batch_120: train_l:1.4010411688118927, train_accuracy:0.44879907024793386, time_count:0.003619670867919922\n",
      "batch_130: train_l:1.3720117302341315, train_accuracy:0.46022185114503816, time_count:0.00423884391784668\n",
      "batch_140: train_l:1.3514938747629206, train_accuracy:0.46617353723404253, time_count:0.004521369934082031\n",
      "batch_150: train_l:1.3297764378667667, train_accuracy:0.47356167218543044, time_count:0.004622220993041992\n",
      "batch_160: train_l:1.3154347065072622, train_accuracy:0.47976513975155277, time_count:0.004440784454345703\n",
      "batch_170: train_l:1.2933920691584984, train_accuracy:0.4878472222222222, time_count:0.003737211227416992\n",
      "batch_180: train_l:1.2725838689514286, train_accuracy:0.4954031422651934, time_count:0.004097461700439453\n",
      "batch_190: train_l:1.2581452568164047, train_accuracy:0.5002454188481675, time_count:0.004995584487915039\n",
      "batch_200: train_l:1.2442157407898216, train_accuracy:0.5053249378109452, time_count:0.003803253173828125\n",
      "batch_210: train_l:1.2295941848890477, train_accuracy:0.5100710900473934, time_count:0.004327535629272461\n",
      "batch_220: train_l:1.2149665682024546, train_accuracy:0.5156780260180995, time_count:0.0036520957946777344\n",
      "batch_230: train_l:1.2046711630635447, train_accuracy:0.5198525432900433, time_count:0.0034945011138916016\n",
      "================================\n",
      "epoch_1: test_acc:0.6581\n",
      "================================\n",
      "batch_0: train_l:0.8743177652359009, train_accuracy:0.67578125, time_count:0.006211280822753906\n",
      "batch_10: train_l:0.882881148294969, train_accuracy:0.6551846590909091, time_count:0.0044841766357421875\n",
      "batch_20: train_l:0.8613832876795814, train_accuracy:0.6553199404761905, time_count:0.003880739212036133\n",
      "batch_30: train_l:0.8792160230298196, train_accuracy:0.655241935483871, time_count:0.004343509674072266\n",
      "batch_40: train_l:0.8725019010101877, train_accuracy:0.6612995426829268, time_count:0.004274845123291016\n",
      "batch_50: train_l:0.8629750679521, train_accuracy:0.6646752450980392, time_count:0.0040857791900634766\n",
      "batch_60: train_l:0.867765616198055, train_accuracy:0.6613729508196722, time_count:0.0039560794830322266\n",
      "batch_70: train_l:0.8617953540573657, train_accuracy:0.6644476232394366, time_count:0.0045964717864990234\n",
      "batch_80: train_l:0.8572818401419087, train_accuracy:0.6639660493827161, time_count:0.003700733184814453\n",
      "batch_90: train_l:0.8516667432837434, train_accuracy:0.6667668269230769, time_count:0.004415750503540039\n",
      "batch_100: train_l:0.8459205273354408, train_accuracy:0.6692450495049505, time_count:0.0045354366302490234\n",
      "batch_110: train_l:0.8418401388434676, train_accuracy:0.6701506193693694, time_count:0.004622936248779297\n",
      "batch_120: train_l:0.8336741904581874, train_accuracy:0.6741348140495868, time_count:0.004116535186767578\n",
      "batch_130: train_l:0.8356194528004596, train_accuracy:0.6739623091603053, time_count:0.0038619041442871094\n",
      "batch_140: train_l:0.8334683158718947, train_accuracy:0.6750886524822695, time_count:0.004059553146362305\n",
      "batch_150: train_l:0.8289572197869913, train_accuracy:0.6772040562913907, time_count:0.0048334598541259766\n",
      "batch_160: train_l:0.8271269409552865, train_accuracy:0.6771156832298136, time_count:0.004883289337158203\n",
      "batch_170: train_l:0.8211385844743739, train_accuracy:0.6794362207602339, time_count:0.004335880279541016\n",
      "batch_180: train_l:0.8134884122985503, train_accuracy:0.6833347720994475, time_count:0.0044918060302734375\n",
      "batch_190: train_l:0.811424716917008, train_accuracy:0.6839618782722513, time_count:0.004323720932006836\n",
      "batch_200: train_l:0.8071736186297972, train_accuracy:0.6853039490049752, time_count:0.0044629573822021484\n",
      "batch_210: train_l:0.8030027902521794, train_accuracy:0.6870927132701422, time_count:0.004378557205200195\n",
      "batch_220: train_l:0.7998612412500166, train_accuracy:0.6884367929864253, time_count:0.003594636917114258\n",
      "batch_230: train_l:0.7970522358303979, train_accuracy:0.689157196969697, time_count:0.0036046504974365234\n",
      "================================\n",
      "epoch_2: test_acc:0.6982\n",
      "================================\n",
      "batch_0: train_l:0.6779135465621948, train_accuracy:0.734375, time_count:0.010294198989868164\n",
      "batch_10: train_l:0.7077208378098228, train_accuracy:0.7283380681818182, time_count:0.005107879638671875\n",
      "batch_20: train_l:0.7222221891085306, train_accuracy:0.7155877976190477, time_count:0.0040705204010009766\n",
      "batch_30: train_l:0.7252918712554439, train_accuracy:0.7171118951612904, time_count:0.003918647766113281\n",
      "batch_40: train_l:0.7186125909409872, train_accuracy:0.7178925304878049, time_count:0.0045185089111328125\n",
      "batch_50: train_l:0.7146113585023319, train_accuracy:0.7210477941176471, time_count:0.004611492156982422\n",
      "batch_60: train_l:0.7061750947451982, train_accuracy:0.7238729508196722, time_count:0.003902912139892578\n",
      "batch_70: train_l:0.7010723352432251, train_accuracy:0.7258472711267606, time_count:0.00426030158996582\n",
      "batch_80: train_l:0.7004975249737869, train_accuracy:0.7257908950617284, time_count:0.004701137542724609\n",
      "batch_90: train_l:0.7032314990902995, train_accuracy:0.7246737637362637, time_count:0.0038022994995117188\n",
      "batch_100: train_l:0.6968138194320226, train_accuracy:0.726871905940594, time_count:0.004308938980102539\n",
      "batch_110: train_l:0.6966894387124895, train_accuracy:0.7261753941441441, time_count:0.004163503646850586\n",
      "batch_120: train_l:0.6953001844981486, train_accuracy:0.7267884814049587, time_count:0.005211591720581055\n",
      "batch_130: train_l:0.6922917361477859, train_accuracy:0.7285603530534351, time_count:0.005052804946899414\n",
      "batch_140: train_l:0.6901582923341305, train_accuracy:0.7294160017730497, time_count:0.005009651184082031\n",
      "batch_150: train_l:0.6870231213948584, train_accuracy:0.73046875, time_count:0.004921436309814453\n",
      "batch_160: train_l:0.6831937069478242, train_accuracy:0.7320215450310559, time_count:0.0049991607666015625\n",
      "batch_170: train_l:0.684460164859281, train_accuracy:0.7309713084795322, time_count:0.004163503646850586\n",
      "batch_180: train_l:0.6835610958752711, train_accuracy:0.7316341505524862, time_count:0.003934621810913086\n",
      "batch_190: train_l:0.6817759774742326, train_accuracy:0.7325343586387435, time_count:0.003972530364990234\n",
      "batch_200: train_l:0.6782203791153372, train_accuracy:0.7342195273631841, time_count:0.003953695297241211\n",
      "batch_210: train_l:0.6787615994706538, train_accuracy:0.7335234004739336, time_count:0.004422664642333984\n",
      "batch_220: train_l:0.67683578697265, train_accuracy:0.7341805712669683, time_count:0.0038499832153320312\n",
      "batch_230: train_l:0.6742085633855878, train_accuracy:0.7348146645021645, time_count:0.0036590099334716797\n",
      "================================\n",
      "epoch_3: test_acc:0.7329\n",
      "================================\n",
      "batch_0: train_l:0.5760147571563721, train_accuracy:0.78515625, time_count:0.005937099456787109\n",
      "batch_10: train_l:0.6157411662015048, train_accuracy:0.7531960227272727, time_count:0.0043182373046875\n",
      "batch_20: train_l:0.6199686867850167, train_accuracy:0.7503720238095238, time_count:0.004103183746337891\n",
      "batch_30: train_l:0.6051298274147895, train_accuracy:0.7604586693548387, time_count:0.004828691482543945\n",
      "batch_40: train_l:0.6227477665354566, train_accuracy:0.7538109756097561, time_count:0.004083156585693359\n",
      "batch_50: train_l:0.61865854789229, train_accuracy:0.7558210784313726, time_count:0.00429224967956543\n",
      "batch_60: train_l:0.6204495532590835, train_accuracy:0.7550589139344263, time_count:0.004418134689331055\n",
      "batch_70: train_l:0.6268060261934576, train_accuracy:0.7524207746478874, time_count:0.004312276840209961\n",
      "batch_80: train_l:0.6267742694895945, train_accuracy:0.7525559413580247, time_count:0.008872032165527344\n",
      "batch_90: train_l:0.6255439333208315, train_accuracy:0.7530906593406593, time_count:0.004604339599609375\n",
      "batch_100: train_l:0.626343182703056, train_accuracy:0.7532100866336634, time_count:0.004700422286987305\n",
      "batch_110: train_l:0.6260881464223604, train_accuracy:0.7533431869369369, time_count:0.0048787593841552734\n",
      "batch_120: train_l:0.6235499882008418, train_accuracy:0.7557463842975206, time_count:0.004944324493408203\n",
      "batch_130: train_l:0.6221872447556211, train_accuracy:0.7565601145038168, time_count:0.003938913345336914\n",
      "batch_140: train_l:0.6230072875817617, train_accuracy:0.7554853723404256, time_count:0.004658699035644531\n",
      "batch_150: train_l:0.6211069903231614, train_accuracy:0.7567777317880795, time_count:0.006079435348510742\n",
      "batch_160: train_l:0.6226846510949342, train_accuracy:0.7563082298136646, time_count:0.004759311676025391\n",
      "batch_170: train_l:0.6204220842548281, train_accuracy:0.7575383771929824, time_count:0.004838228225708008\n",
      "batch_180: train_l:0.618861080039272, train_accuracy:0.758697341160221, time_count:0.004390239715576172\n",
      "batch_190: train_l:0.6177371963468522, train_accuracy:0.7593463678010471, time_count:0.004530906677246094\n",
      "batch_200: train_l:0.618083792391108, train_accuracy:0.7592894900497512, time_count:0.004952907562255859\n",
      "batch_210: train_l:0.6157126874437829, train_accuracy:0.7603487855450237, time_count:0.004933595657348633\n",
      "batch_220: train_l:0.6159357413716985, train_accuracy:0.7604638009049773, time_count:0.004147052764892578\n",
      "batch_230: train_l:0.6144359985213259, train_accuracy:0.7610592532467533, time_count:0.004093170166015625\n",
      "================================\n",
      "epoch_4: test_acc:0.7532\n",
      "================================\n",
      "batch_0: train_l:0.6220636367797852, train_accuracy:0.75390625, time_count:0.0083465576171875\n",
      "batch_10: train_l:0.5502236675132405, train_accuracy:0.79296875, time_count:0.004430294036865234\n",
      "batch_20: train_l:0.5430217626548949, train_accuracy:0.7938988095238095, time_count:0.005022287368774414\n",
      "batch_30: train_l:0.5508831739425659, train_accuracy:0.7913306451612904, time_count:0.005007505416870117\n",
      "batch_40: train_l:0.5555756993410064, train_accuracy:0.7882050304878049, time_count:0.004615306854248047\n",
      "batch_50: train_l:0.5592078584081986, train_accuracy:0.7867647058823529, time_count:0.0043866634368896484\n",
      "batch_60: train_l:0.5638212644663013, train_accuracy:0.7861808401639344, time_count:0.0044672489166259766\n",
      "batch_70: train_l:0.56283921549018, train_accuracy:0.7858714788732394, time_count:0.004564046859741211\n",
      "batch_80: train_l:0.5731980922045531, train_accuracy:0.7814911265432098, time_count:0.004983425140380859\n",
      "batch_90: train_l:0.572579739512978, train_accuracy:0.7809065934065934, time_count:0.004676342010498047\n",
      "batch_100: train_l:0.5714996681355013, train_accuracy:0.7817914603960396, time_count:0.004555463790893555\n",
      "batch_110: train_l:0.5725125450271744, train_accuracy:0.7805109797297297, time_count:0.004762887954711914\n",
      "batch_120: train_l:0.5693653033784598, train_accuracy:0.7804752066115702, time_count:0.0047109127044677734\n",
      "batch_130: train_l:0.572785496711731, train_accuracy:0.7796696087786259, time_count:0.004492521286010742\n",
      "batch_140: train_l:0.5702129940614633, train_accuracy:0.7802526595744681, time_count:0.004328489303588867\n",
      "batch_150: train_l:0.5697340268567698, train_accuracy:0.7804739238410596, time_count:0.004991769790649414\n",
      "batch_160: train_l:0.5684202256039803, train_accuracy:0.7803280279503105, time_count:0.0051839351654052734\n",
      "batch_170: train_l:0.568813822597091, train_accuracy:0.7801306652046783, time_count:0.004851102828979492\n",
      "batch_180: train_l:0.5681297209381398, train_accuracy:0.7802788328729282, time_count:0.004684925079345703\n",
      "batch_190: train_l:0.5680864139689201, train_accuracy:0.7804523887434555, time_count:0.0047185420989990234\n",
      "batch_200: train_l:0.5664243895319564, train_accuracy:0.7811528296019901, time_count:0.004727602005004883\n",
      "batch_210: train_l:0.5653921631275195, train_accuracy:0.781564721563981, time_count:0.0046024322509765625\n",
      "batch_220: train_l:0.5641330859510068, train_accuracy:0.7819039875565611, time_count:0.004553794860839844\n",
      "batch_230: train_l:0.564906626423716, train_accuracy:0.7815712932900433, time_count:0.0041081905364990234\n",
      "================================\n",
      "epoch_5: test_acc:0.7478\n",
      "================================\n",
      "batch_0: train_l:0.546356737613678, train_accuracy:0.78515625, time_count:0.0048139095306396484\n",
      "batch_10: train_l:0.5413462546738711, train_accuracy:0.7990056818181818, time_count:0.0048675537109375\n",
      "batch_20: train_l:0.5455167392889658, train_accuracy:0.7912946428571429, time_count:0.003876209259033203\n",
      "batch_30: train_l:0.5511056271291548, train_accuracy:0.7879284274193549, time_count:0.006532430648803711\n",
      "batch_40: train_l:0.5440301836990729, train_accuracy:0.7906821646341463, time_count:0.004878520965576172\n",
      "batch_50: train_l:0.5432408212446699, train_accuracy:0.7909773284313726, time_count:0.004932403564453125\n",
      "batch_60: train_l:0.5346107697877728, train_accuracy:0.7939933401639344, time_count:0.004695892333984375\n",
      "batch_70: train_l:0.535679558213328, train_accuracy:0.7930237676056338, time_count:0.00505828857421875\n",
      "batch_80: train_l:0.5331779622737273, train_accuracy:0.7941743827160493, time_count:0.005006313323974609\n",
      "batch_90: train_l:0.5314603650962914, train_accuracy:0.7940848214285714, time_count:0.0044803619384765625\n",
      "batch_100: train_l:0.5328153100344214, train_accuracy:0.7935102103960396, time_count:0.0044269561767578125\n",
      "batch_110: train_l:0.5298557214371793, train_accuracy:0.7950802364864865, time_count:0.0041675567626953125\n",
      "batch_120: train_l:0.527909429359042, train_accuracy:0.7964230371900827, time_count:0.004927158355712891\n",
      "batch_130: train_l:0.5291656480945703, train_accuracy:0.7955927958015268, time_count:0.004750490188598633\n",
      "batch_140: train_l:0.5318847154894619, train_accuracy:0.794104609929078, time_count:0.005124807357788086\n",
      "batch_150: train_l:0.5290111771087773, train_accuracy:0.7954263245033113, time_count:0.00435328483581543\n",
      "batch_160: train_l:0.5281204044448663, train_accuracy:0.7962199145962733, time_count:0.004344463348388672\n",
      "batch_170: train_l:0.5278263966939603, train_accuracy:0.7963952850877193, time_count:0.004487752914428711\n",
      "batch_180: train_l:0.5275671826212446, train_accuracy:0.7965944406077348, time_count:0.005062103271484375\n",
      "batch_190: train_l:0.52723647802288, train_accuracy:0.7975089986910995, time_count:0.005192279815673828\n",
      "batch_200: train_l:0.5270781807638519, train_accuracy:0.7976912313432836, time_count:0.005031108856201172\n",
      "batch_210: train_l:0.5255654109597772, train_accuracy:0.7985781990521327, time_count:0.004594564437866211\n",
      "batch_220: train_l:0.5253373389869793, train_accuracy:0.799031391402715, time_count:0.00421905517578125\n",
      "batch_230: train_l:0.5242319094154225, train_accuracy:0.7997835497835498, time_count:0.003943443298339844\n",
      "================================\n",
      "epoch_6: test_acc:0.8035\n",
      "================================\n",
      "batch_0: train_l:0.4465029239654541, train_accuracy:0.828125, time_count:0.006563901901245117\n",
      "batch_10: train_l:0.5140449485995553, train_accuracy:0.8103693181818182, time_count:0.005133628845214844\n",
      "batch_20: train_l:0.5112858613332113, train_accuracy:0.8104538690476191, time_count:0.005214214324951172\n",
      "batch_30: train_l:0.5001363879249942, train_accuracy:0.8109879032258065, time_count:0.004393815994262695\n",
      "batch_40: train_l:0.49893556716965465, train_accuracy:0.8106897865853658, time_count:0.004082679748535156\n",
      "batch_50: train_l:0.49919140105154, train_accuracy:0.8103553921568627, time_count:0.004174232482910156\n",
      "batch_60: train_l:0.4967928357788774, train_accuracy:0.8121798155737705, time_count:0.004125833511352539\n",
      "batch_70: train_l:0.49473626848677515, train_accuracy:0.8123349471830986, time_count:0.0041751861572265625\n",
      "batch_80: train_l:0.4978403699250869, train_accuracy:0.8106192129629629, time_count:0.004760026931762695\n",
      "batch_90: train_l:0.49895264257441513, train_accuracy:0.8097527472527473, time_count:0.004652976989746094\n",
      "batch_100: train_l:0.4986048688982973, train_accuracy:0.809792698019802, time_count:0.0051424503326416016\n",
      "batch_110: train_l:0.4986610828756212, train_accuracy:0.809543918918919, time_count:0.004671812057495117\n",
      "batch_120: train_l:0.4990878119941585, train_accuracy:0.8100787706611571, time_count:0.004680633544921875\n",
      "batch_130: train_l:0.49971599160259916, train_accuracy:0.8097864980916031, time_count:0.004857063293457031\n",
      "batch_140: train_l:0.49756865763495156, train_accuracy:0.8103113918439716, time_count:0.004494190216064453\n",
      "batch_150: train_l:0.4962080211828876, train_accuracy:0.8111030629139073, time_count:0.0047261714935302734\n",
      "batch_160: train_l:0.49884175606395886, train_accuracy:0.809952445652174, time_count:0.003997087478637695\n",
      "batch_170: train_l:0.49732677054684066, train_accuracy:0.8110836988304093, time_count:0.004462480545043945\n",
      "batch_180: train_l:0.496834740289667, train_accuracy:0.8115072513812155, time_count:0.00444793701171875\n",
      "batch_190: train_l:0.49821174550430936, train_accuracy:0.8105571007853403, time_count:0.004771709442138672\n",
      "batch_200: train_l:0.4988533552013226, train_accuracy:0.8102067786069652, time_count:0.004878044128417969\n",
      "batch_210: train_l:0.4982538217616872, train_accuracy:0.811037470379147, time_count:0.004332065582275391\n",
      "batch_220: train_l:0.4971168727626628, train_accuracy:0.8116162330316742, time_count:0.003971576690673828\n",
      "batch_230: train_l:0.49715595160211834, train_accuracy:0.8116883116883117, time_count:0.003930807113647461\n",
      "================================\n",
      "epoch_7: test_acc:0.7983\n",
      "================================\n",
      "batch_0: train_l:0.4878314733505249, train_accuracy:0.83203125, time_count:0.005816221237182617\n",
      "batch_10: train_l:0.4874843873760917, train_accuracy:0.8146306818181818, time_count:0.004828453063964844\n",
      "batch_20: train_l:0.47790341292108807, train_accuracy:0.8212425595238095, time_count:0.005079746246337891\n",
      "batch_30: train_l:0.4811014359997165, train_accuracy:0.8209425403225806, time_count:0.005120992660522461\n",
      "batch_40: train_l:0.4769595519798558, train_accuracy:0.821265243902439, time_count:0.0047681331634521484\n",
      "batch_50: train_l:0.4762841948107177, train_accuracy:0.8191636029411765, time_count:0.004418373107910156\n",
      "batch_60: train_l:0.48338237502535836, train_accuracy:0.8155737704918032, time_count:0.0046994686126708984\n",
      "batch_70: train_l:0.4798235750534165, train_accuracy:0.8182768485915493, time_count:0.005232334136962891\n",
      "batch_80: train_l:0.4828144499549159, train_accuracy:0.8171778549382716, time_count:0.0052678585052490234\n",
      "batch_90: train_l:0.4804490621273334, train_accuracy:0.8184237637362637, time_count:0.004628896713256836\n",
      "batch_100: train_l:0.48257818788585094, train_accuracy:0.8173731435643564, time_count:0.005498647689819336\n",
      "batch_110: train_l:0.4814694002941922, train_accuracy:0.8182010135135135, time_count:0.004929542541503906\n",
      "batch_120: train_l:0.4792730857518094, train_accuracy:0.8192471590909091, time_count:0.00472259521484375\n",
      "batch_130: train_l:0.4758078733473334, train_accuracy:0.8205212309160306, time_count:0.004069089889526367\n",
      "batch_140: train_l:0.4745050106488221, train_accuracy:0.8213098404255319, time_count:0.004094362258911133\n",
      "batch_150: train_l:0.4731771590693897, train_accuracy:0.8218387831125827, time_count:0.004022121429443359\n",
      "batch_160: train_l:0.4738596983207679, train_accuracy:0.8219380822981367, time_count:0.004127025604248047\n",
      "batch_170: train_l:0.47324915831549125, train_accuracy:0.8218887061403509, time_count:0.0047016143798828125\n",
      "batch_180: train_l:0.4729139137992543, train_accuracy:0.822082182320442, time_count:0.004334688186645508\n",
      "batch_190: train_l:0.47267411485392385, train_accuracy:0.822132689790576, time_count:0.005352973937988281\n",
      "batch_200: train_l:0.47111536036083357, train_accuracy:0.8227611940298507, time_count:0.004856586456298828\n",
      "batch_210: train_l:0.47022537399807246, train_accuracy:0.8226821682464455, time_count:0.004896879196166992\n",
      "batch_220: train_l:0.4703646075671615, train_accuracy:0.8227870475113123, time_count:0.003964424133300781\n",
      "batch_230: train_l:0.46981075393173083, train_accuracy:0.8232041396103896, time_count:0.004206180572509766\n",
      "================================\n",
      "epoch_8: test_acc:0.799\n",
      "================================\n",
      "batch_0: train_l:0.5266607999801636, train_accuracy:0.81640625, time_count:0.006337404251098633\n",
      "batch_10: train_l:0.4602647911418568, train_accuracy:0.8277698863636364, time_count:0.01775383949279785\n",
      "batch_20: train_l:0.4525084027222225, train_accuracy:0.8314732142857143, time_count:0.00468754768371582\n",
      "batch_30: train_l:0.4481663184781228, train_accuracy:0.8350554435483871, time_count:0.004755973815917969\n",
      "batch_40: train_l:0.45450088309078684, train_accuracy:0.8323170731707317, time_count:0.004042148590087891\n",
      "batch_50: train_l:0.4519043144057779, train_accuracy:0.8336397058823529, time_count:0.004670858383178711\n",
      "batch_60: train_l:0.44668397551677264, train_accuracy:0.8358094262295082, time_count:0.004289150238037109\n",
      "batch_70: train_l:0.44604597251180195, train_accuracy:0.8354423415492958, time_count:0.004893064498901367\n",
      "batch_80: train_l:0.4487727501510102, train_accuracy:0.8350212191358025, time_count:0.0052182674407958984\n",
      "batch_90: train_l:0.4513926620666797, train_accuracy:0.8344350961538461, time_count:0.005060672760009766\n",
      "batch_100: train_l:0.45264122332676804, train_accuracy:0.8341970915841584, time_count:0.004054546356201172\n",
      "batch_110: train_l:0.45347726103421804, train_accuracy:0.8337556306306306, time_count:0.004528045654296875\n",
      "batch_120: train_l:0.45448527306564585, train_accuracy:0.8336776859504132, time_count:0.004026651382446289\n",
      "batch_130: train_l:0.45478835906691223, train_accuracy:0.8329854484732825, time_count:0.0040628910064697266\n",
      "batch_140: train_l:0.4525355096404434, train_accuracy:0.8330008865248227, time_count:0.004244565963745117\n",
      "batch_150: train_l:0.4533563605602214, train_accuracy:0.8325486341059603, time_count:0.005143880844116211\n",
      "batch_160: train_l:0.45275778466870326, train_accuracy:0.8326378105590062, time_count:0.00443577766418457\n",
      "batch_170: train_l:0.4514542934838791, train_accuracy:0.83296783625731, time_count:0.004461050033569336\n",
      "batch_180: train_l:0.45125174950499564, train_accuracy:0.8330455801104972, time_count:0.0047762393951416016\n",
      "batch_190: train_l:0.4511789907335611, train_accuracy:0.8331969895287958, time_count:0.005287647247314453\n",
      "batch_200: train_l:0.4505472715517775, train_accuracy:0.8336054104477612, time_count:0.00506591796875\n",
      "batch_210: train_l:0.45000361238045716, train_accuracy:0.8337714751184834, time_count:0.0045948028564453125\n",
      "batch_220: train_l:0.4487607403578262, train_accuracy:0.8343467194570136, time_count:0.0041120052337646484\n",
      "batch_230: train_l:0.4486109351182913, train_accuracy:0.8342972132034632, time_count:0.004155635833740234\n",
      "================================\n",
      "epoch_9: test_acc:0.8182\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "# LeNet\n",
    "# input: nx1x28x28\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import load_data_fashion_mnist\n",
    "from d2l import train_ch6_gpu\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),  # nx6x28x28\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),  # nx6x14x14\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),  # nx16x10x10\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),  # nx16x5x5\n",
    "    nn.Flatten(),  # nx400\n",
    "    #  full connection block\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")\n",
    "\n",
    "X = torch.rand((1,1,28,28),dtype=torch.float32)\n",
    "\n",
    "net(X)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t\\t',X.shape)\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "lr, num_epochs = 0.9, 10\n",
    "train_ch6_gpu(net,train_iter=train_iter,test_iter=test_iter,num_epochs=num_epochs,lr=lr,device='cuda:0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t\t torch.Size([1, 6, 28, 28])\n",
      "BatchNorm2d output shape: \t\t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t\t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t\t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t\t torch.Size([1, 16, 10, 10])\n",
      "BatchNorm2d output shape: \t\t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t\t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t\t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t\t torch.Size([1, 400])\n",
      "Linear output shape: \t\t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t\t torch.Size([1, 120])\n",
      "Linear output shape: \t\t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t\t torch.Size([1, 84])\n",
      "Linear output shape: \t\t torch.Size([1, 10])\n",
      "net will be trained on cuda:0\n",
      "batch_0: train_l:2.4651753902435303, train_accuracy:0.125, time_count:0.245985746383667\n",
      "batch_10: train_l:2.441270524805242, train_accuracy:0.10653409090909091, time_count:0.004595518112182617\n",
      "batch_20: train_l:2.333327259336199, train_accuracy:0.13392857142857142, time_count:0.004548549652099609\n",
      "batch_30: train_l:2.2450547026049708, train_accuracy:0.15498991935483872, time_count:0.004548549652099609\n",
      "batch_40: train_l:2.1704103568705118, train_accuracy:0.17835365853658536, time_count:0.004982471466064453\n",
      "batch_50: train_l:2.053380671669455, train_accuracy:0.22342218137254902, time_count:0.0038123130798339844\n",
      "batch_60: train_l:1.9753784156236491, train_accuracy:0.2463498975409836, time_count:0.004067182540893555\n",
      "batch_70: train_l:1.8801727479612325, train_accuracy:0.27899427816901406, time_count:0.003824472427368164\n",
      "batch_80: train_l:1.7966011556578272, train_accuracy:0.3070505401234568, time_count:0.0045816898345947266\n",
      "batch_90: train_l:1.721940619604928, train_accuracy:0.33143028846153844, time_count:0.0044634342193603516\n",
      "batch_100: train_l:1.676596460366013, train_accuracy:0.34688273514851486, time_count:0.0042629241943359375\n",
      "batch_110: train_l:1.6229197624567393, train_accuracy:0.3692286036036036, time_count:0.0038166046142578125\n",
      "batch_120: train_l:1.5723150116352995, train_accuracy:0.3886880165289256, time_count:0.003854990005493164\n",
      "batch_130: train_l:1.5325639912190328, train_accuracy:0.40314885496183206, time_count:0.004248142242431641\n",
      "batch_140: train_l:1.4907650660115777, train_accuracy:0.4201850620567376, time_count:0.0038003921508789062\n",
      "batch_150: train_l:1.462401752835078, train_accuracy:0.4314207367549669, time_count:0.0040323734283447266\n",
      "batch_160: train_l:1.4279106751732205, train_accuracy:0.44407511645962733, time_count:0.003808736801147461\n",
      "batch_170: train_l:1.4187084600242257, train_accuracy:0.45063505116959063, time_count:0.0038139820098876953\n",
      "batch_180: train_l:1.3926107629886648, train_accuracy:0.46016056629834257, time_count:0.004026174545288086\n",
      "batch_190: train_l:1.3658837098725802, train_accuracy:0.47054973821989526, time_count:0.0038695335388183594\n",
      "batch_200: train_l:1.340573900967688, train_accuracy:0.4806630907960199, time_count:0.004405021667480469\n",
      "batch_210: train_l:1.317114793858822, train_accuracy:0.4894845971563981, time_count:0.0046770572662353516\n",
      "batch_220: train_l:1.2930005802288314, train_accuracy:0.49883342760180993, time_count:0.0038826465606689453\n",
      "batch_230: train_l:1.2743450183889051, train_accuracy:0.5058509199134199, time_count:0.0037314891815185547\n",
      "================================\n",
      "epoch_0: test_acc:0.6738\n",
      "================================\n",
      "batch_0: train_l:0.8130786418914795, train_accuracy:0.6875, time_count:0.006139039993286133\n",
      "batch_10: train_l:0.7627925926988776, train_accuracy:0.7105823863636364, time_count:0.0038585662841796875\n",
      "batch_20: train_l:0.7682664394378662, train_accuracy:0.7033110119047619, time_count:0.00388336181640625\n",
      "batch_30: train_l:0.7612536472658957, train_accuracy:0.7009828629032258, time_count:0.0038213729858398438\n",
      "batch_40: train_l:0.7533292043499831, train_accuracy:0.7019817073170732, time_count:0.004374980926513672\n",
      "batch_50: train_l:0.750845826139637, train_accuracy:0.7028186274509803, time_count:0.0040225982666015625\n",
      "batch_60: train_l:0.7402213284226714, train_accuracy:0.7067110655737705, time_count:0.004334449768066406\n",
      "batch_70: train_l:0.7352536899942748, train_accuracy:0.7096170774647887, time_count:0.004094123840332031\n",
      "batch_80: train_l:0.7389284055909993, train_accuracy:0.7081886574074074, time_count:0.0043773651123046875\n",
      "batch_90: train_l:0.7342287943913386, train_accuracy:0.7095209478021978, time_count:0.0047130584716796875\n",
      "batch_100: train_l:0.7320660824822908, train_accuracy:0.7112082301980198, time_count:0.004926204681396484\n",
      "batch_110: train_l:0.7253217820648674, train_accuracy:0.714527027027027, time_count:0.004770517349243164\n",
      "batch_120: train_l:0.7196190987736726, train_accuracy:0.7162642045454546, time_count:0.005029439926147461\n",
      "batch_130: train_l:0.7141095149608059, train_accuracy:0.7182729007633588, time_count:0.00446772575378418\n",
      "batch_140: train_l:0.7101217017951587, train_accuracy:0.7201074911347518, time_count:0.003954172134399414\n",
      "batch_150: train_l:0.7053464094534615, train_accuracy:0.7223199503311258, time_count:0.003965854644775391\n",
      "batch_160: train_l:0.7002441253721344, train_accuracy:0.7247185559006211, time_count:0.004053831100463867\n",
      "batch_170: train_l:0.6981049884132474, train_accuracy:0.7253746345029239, time_count:0.004159212112426758\n",
      "batch_180: train_l:0.6943821561270656, train_accuracy:0.7266704074585635, time_count:0.004826545715332031\n",
      "batch_190: train_l:0.6898310015963011, train_accuracy:0.7283622382198953, time_count:0.004671335220336914\n",
      "batch_200: train_l:0.6903661302666166, train_accuracy:0.7281755286069652, time_count:0.00408625602722168\n",
      "batch_210: train_l:0.6860161350236684, train_accuracy:0.7300244372037915, time_count:0.004243135452270508\n",
      "batch_220: train_l:0.6842526165068958, train_accuracy:0.7304333993212669, time_count:0.004421234130859375\n",
      "batch_230: train_l:0.6814202330845259, train_accuracy:0.7320921266233766, time_count:0.003953695297241211\n",
      "================================\n",
      "epoch_1: test_acc:0.743\n",
      "================================\n",
      "batch_0: train_l:0.5547205805778503, train_accuracy:0.81640625, time_count:0.00788259506225586\n",
      "batch_10: train_l:0.5739269581708041, train_accuracy:0.7848011363636364, time_count:0.0041735172271728516\n",
      "batch_20: train_l:0.5954171873274303, train_accuracy:0.7700892857142857, time_count:0.0040988922119140625\n",
      "batch_30: train_l:0.6033243479267243, train_accuracy:0.7675151209677419, time_count:0.004334449768066406\n",
      "batch_40: train_l:0.605843772248524, train_accuracy:0.7651486280487805, time_count:0.0041692256927490234\n",
      "batch_50: train_l:0.600324811888676, train_accuracy:0.7660845588235294, time_count:0.003816366195678711\n",
      "batch_60: train_l:0.5941515139869002, train_accuracy:0.7705558401639344, time_count:0.0052263736724853516\n",
      "batch_70: train_l:0.5926068735794282, train_accuracy:0.7711817781690141, time_count:0.00441288948059082\n",
      "batch_80: train_l:0.5888987051116096, train_accuracy:0.773485725308642, time_count:0.003897428512573242\n",
      "batch_90: train_l:0.5861330769219242, train_accuracy:0.7737379807692307, time_count:0.0040280818939208984\n",
      "batch_100: train_l:0.5854550437762005, train_accuracy:0.7737082301980198, time_count:0.0038890838623046875\n",
      "batch_110: train_l:0.5857019730516382, train_accuracy:0.7746692004504504, time_count:0.004205226898193359\n",
      "batch_120: train_l:0.5819743524405582, train_accuracy:0.7769886363636364, time_count:0.005147218704223633\n",
      "batch_130: train_l:0.5792142255160645, train_accuracy:0.7783277671755725, time_count:0.0046176910400390625\n",
      "batch_140: train_l:0.5786244017435304, train_accuracy:0.777842420212766, time_count:0.004273176193237305\n",
      "batch_150: train_l:0.5783383741678781, train_accuracy:0.777421357615894, time_count:0.004580259323120117\n",
      "batch_160: train_l:0.5762873719567838, train_accuracy:0.778702445652174, time_count:0.004242897033691406\n",
      "batch_170: train_l:0.5748404093653138, train_accuracy:0.779171235380117, time_count:0.0039980411529541016\n",
      "batch_180: train_l:0.5710884987978645, train_accuracy:0.7808615331491713, time_count:0.0046498775482177734\n",
      "batch_190: train_l:0.5682947145706696, train_accuracy:0.7819453534031413, time_count:0.004984378814697266\n",
      "batch_200: train_l:0.5652350962755099, train_accuracy:0.7830379353233831, time_count:0.004216670989990234\n",
      "batch_210: train_l:0.5636144305857437, train_accuracy:0.7836566943127962, time_count:0.004210472106933594\n",
      "batch_220: train_l:0.5632805069107815, train_accuracy:0.7836361708144797, time_count:0.0038704872131347656\n",
      "batch_230: train_l:0.5611239362072635, train_accuracy:0.7844967532467533, time_count:0.0037865638732910156\n",
      "================================\n",
      "epoch_2: test_acc:0.7816\n",
      "================================\n",
      "batch_0: train_l:0.48764505982398987, train_accuracy:0.8125, time_count:0.00628972053527832\n",
      "batch_10: train_l:0.5215744105252352, train_accuracy:0.7965198863636364, time_count:0.004172325134277344\n",
      "batch_20: train_l:0.5094834807373229, train_accuracy:0.8050595238095238, time_count:0.0044705867767333984\n",
      "batch_30: train_l:0.5196879006201222, train_accuracy:0.8015372983870968, time_count:0.0039052963256835938\n",
      "batch_40: train_l:0.5159725408728529, train_accuracy:0.8028772865853658, time_count:0.004065513610839844\n",
      "batch_50: train_l:0.5104227843237858, train_accuracy:0.8049172794117647, time_count:0.004098415374755859\n",
      "batch_60: train_l:0.5142783131755766, train_accuracy:0.8033427254098361, time_count:0.004438877105712891\n",
      "batch_70: train_l:0.5186935852111225, train_accuracy:0.800506161971831, time_count:0.00453639030456543\n",
      "batch_80: train_l:0.5163142699518322, train_accuracy:0.8014081790123457, time_count:0.003942728042602539\n",
      "batch_90: train_l:0.5156955250671932, train_accuracy:0.8027987637362637, time_count:0.004018068313598633\n",
      "batch_100: train_l:0.5118603405385914, train_accuracy:0.8050355816831684, time_count:0.004049777984619141\n",
      "batch_110: train_l:0.5099509895384848, train_accuracy:0.8069045608108109, time_count:0.003984212875366211\n",
      "batch_120: train_l:0.5078719800168817, train_accuracy:0.8081095041322314, time_count:0.004428386688232422\n",
      "batch_130: train_l:0.5057188499974841, train_accuracy:0.8085341125954199, time_count:0.003941059112548828\n",
      "batch_140: train_l:0.5050382519021948, train_accuracy:0.8087322695035462, time_count:0.0039370059967041016\n",
      "batch_150: train_l:0.5057243229142877, train_accuracy:0.8078435430463576, time_count:0.004101753234863281\n",
      "batch_160: train_l:0.5047147159250627, train_accuracy:0.8083511257763976, time_count:0.004745006561279297\n",
      "batch_170: train_l:0.501641275241361, train_accuracy:0.8098044590643275, time_count:0.0038797855377197266\n",
      "batch_180: train_l:0.49961305652534105, train_accuracy:0.8108598066298343, time_count:0.004943370819091797\n",
      "batch_190: train_l:0.5016249355845427, train_accuracy:0.8102503272251309, time_count:0.00437474250793457\n",
      "batch_200: train_l:0.500280352077674, train_accuracy:0.8110230099502488, time_count:0.004247903823852539\n",
      "batch_210: train_l:0.49708953429172387, train_accuracy:0.8125740521327014, time_count:0.0045168399810791016\n",
      "batch_220: train_l:0.498835271435086, train_accuracy:0.8119343891402715, time_count:0.0044972896575927734\n",
      "batch_230: train_l:0.49853857422803904, train_accuracy:0.8123478084415584, time_count:0.0038940906524658203\n",
      "================================\n",
      "epoch_3: test_acc:0.805\n",
      "================================\n",
      "batch_0: train_l:0.4664832353591919, train_accuracy:0.83984375, time_count:0.008411407470703125\n",
      "batch_10: train_l:0.49589464881203393, train_accuracy:0.8068181818181818, time_count:0.005667924880981445\n",
      "batch_20: train_l:0.4951509066990444, train_accuracy:0.8054315476190477, time_count:0.005726337432861328\n",
      "batch_30: train_l:0.4795994114491247, train_accuracy:0.8146421370967742, time_count:0.005578279495239258\n",
      "batch_40: train_l:0.47734899927930136, train_accuracy:0.8142149390243902, time_count:0.004569292068481445\n",
      "batch_50: train_l:0.4823041318678388, train_accuracy:0.8128829656862745, time_count:0.005760908126831055\n",
      "batch_60: train_l:0.47594106881344905, train_accuracy:0.8162781762295082, time_count:0.0057904720306396484\n",
      "batch_70: train_l:0.4749783462202045, train_accuracy:0.8175616197183099, time_count:0.005773782730102539\n",
      "batch_80: train_l:0.4698902357507635, train_accuracy:0.820264274691358, time_count:0.004915475845336914\n",
      "batch_90: train_l:0.4703042965668898, train_accuracy:0.8206129807692307, time_count:0.004701137542724609\n",
      "batch_100: train_l:0.4663798637909464, train_accuracy:0.822555693069307, time_count:0.004785060882568359\n",
      "batch_110: train_l:0.4643246093848804, train_accuracy:0.8236204954954955, time_count:0.004227161407470703\n",
      "batch_120: train_l:0.46204204894294426, train_accuracy:0.8251226756198347, time_count:0.005310773849487305\n",
      "batch_130: train_l:0.46394723881291977, train_accuracy:0.8241889312977099, time_count:0.004971504211425781\n",
      "batch_140: train_l:0.46485266765804156, train_accuracy:0.8239417109929078, time_count:0.004417896270751953\n",
      "batch_150: train_l:0.46395363337946255, train_accuracy:0.8243998344370861, time_count:0.007117748260498047\n",
      "batch_160: train_l:0.4613311038994641, train_accuracy:0.8257230201863354, time_count:0.004835844039916992\n",
      "batch_170: train_l:0.4604354333459285, train_accuracy:0.8259320175438597, time_count:0.005266904830932617\n",
      "batch_180: train_l:0.4607563031971125, train_accuracy:0.8260531767955801, time_count:0.004822492599487305\n",
      "batch_190: train_l:0.46356063878348985, train_accuracy:0.8249550065445026, time_count:0.004664421081542969\n",
      "batch_200: train_l:0.46621353027239365, train_accuracy:0.8244519589552238, time_count:0.004874706268310547\n",
      "batch_210: train_l:0.46369836002729514, train_accuracy:0.825940462085308, time_count:0.004922151565551758\n",
      "batch_220: train_l:0.46212181745611164, train_accuracy:0.8268523755656109, time_count:0.004091739654541016\n",
      "batch_230: train_l:0.46099919145241447, train_accuracy:0.8275331439393939, time_count:0.0039958953857421875\n",
      "================================\n",
      "epoch_4: test_acc:0.7758\n",
      "================================\n",
      "batch_0: train_l:0.41724300384521484, train_accuracy:0.83984375, time_count:0.005969047546386719\n",
      "batch_10: train_l:0.42176098986105487, train_accuracy:0.8458806818181818, time_count:0.0057108402252197266\n",
      "batch_20: train_l:0.4093369401636578, train_accuracy:0.8502604166666666, time_count:0.004490852355957031\n",
      "batch_30: train_l:0.41551322321737966, train_accuracy:0.8490423387096774, time_count:0.005560874938964844\n",
      "batch_40: train_l:0.4202372366335334, train_accuracy:0.8481326219512195, time_count:0.0044209957122802734\n",
      "batch_50: train_l:0.42493513401816874, train_accuracy:0.8442095588235294, time_count:0.005016803741455078\n",
      "batch_60: train_l:0.4230892433494818, train_accuracy:0.8440061475409836, time_count:0.004991054534912109\n",
      "batch_70: train_l:0.42452182190518983, train_accuracy:0.8433648767605634, time_count:0.005000591278076172\n",
      "batch_80: train_l:0.4234933989283479, train_accuracy:0.8442804783950617, time_count:0.0046193599700927734\n",
      "batch_90: train_l:0.4259391849512582, train_accuracy:0.8432778159340659, time_count:0.0044825077056884766\n",
      "batch_100: train_l:0.4252527093533242, train_accuracy:0.8440207301980198, time_count:0.005006074905395508\n",
      "batch_110: train_l:0.42557080103470396, train_accuracy:0.844066722972973, time_count:0.005354881286621094\n",
      "batch_120: train_l:0.42479416260049363, train_accuracy:0.8443310950413223, time_count:0.005320072174072266\n",
      "batch_130: train_l:0.4261144695391182, train_accuracy:0.8438990935114504, time_count:0.005030632019042969\n",
      "batch_140: train_l:0.4246082379885599, train_accuracy:0.8439439273049646, time_count:0.004971742630004883\n",
      "batch_150: train_l:0.42318490562060024, train_accuracy:0.8446554221854304, time_count:0.004786491394042969\n",
      "batch_160: train_l:0.4219082956728728, train_accuracy:0.8449873835403726, time_count:0.005044460296630859\n",
      "batch_170: train_l:0.420708313671469, train_accuracy:0.8456231725146199, time_count:0.0052068233489990234\n",
      "batch_180: train_l:0.41982839466458527, train_accuracy:0.8462102900552486, time_count:0.005600452423095703\n",
      "batch_190: train_l:0.4188770377199063, train_accuracy:0.846715477748691, time_count:0.004506826400756836\n",
      "batch_200: train_l:0.4187009040989093, train_accuracy:0.8466845460199005, time_count:0.004795551300048828\n",
      "batch_210: train_l:0.4185881774289913, train_accuracy:0.8466935722748815, time_count:0.0051670074462890625\n",
      "batch_220: train_l:0.41802519411522876, train_accuracy:0.8470906391402715, time_count:0.0046253204345703125\n",
      "batch_230: train_l:0.4182683451351149, train_accuracy:0.8467938311688312, time_count:0.0046007633209228516\n",
      "================================\n",
      "epoch_5: test_acc:0.6819\n",
      "================================\n",
      "batch_0: train_l:0.41804924607276917, train_accuracy:0.85546875, time_count:0.0069353580474853516\n",
      "batch_10: train_l:0.41564057631926105, train_accuracy:0.8465909090909091, time_count:0.0042989253997802734\n",
      "batch_20: train_l:0.4007122019926707, train_accuracy:0.8487723214285714, time_count:0.0055806636810302734\n",
      "batch_30: train_l:0.40746646638839473, train_accuracy:0.8450100806451613, time_count:0.005191802978515625\n",
      "batch_40: train_l:0.39496030603967064, train_accuracy:0.8495617378048781, time_count:0.004910945892333984\n",
      "batch_50: train_l:0.3949458774398355, train_accuracy:0.8526348039215687, time_count:0.004903078079223633\n",
      "batch_60: train_l:0.39513657571839506, train_accuracy:0.8530353483606558, time_count:0.005245685577392578\n",
      "batch_70: train_l:0.39403391556001044, train_accuracy:0.8546985035211268, time_count:0.00574183464050293\n",
      "batch_80: train_l:0.3946360338617254, train_accuracy:0.8545042438271605, time_count:0.0045642852783203125\n",
      "batch_90: train_l:0.39575946200024953, train_accuracy:0.8538375686813187, time_count:0.0042417049407958984\n",
      "batch_100: train_l:0.39341601493335004, train_accuracy:0.8548499381188119, time_count:0.004279613494873047\n",
      "batch_110: train_l:0.3956919870935045, train_accuracy:0.8548001126126126, time_count:0.004289388656616211\n",
      "batch_120: train_l:0.39373852250989805, train_accuracy:0.85521048553719, time_count:0.0046367645263671875\n",
      "batch_130: train_l:0.3941399903242825, train_accuracy:0.8551705629770993, time_count:0.004560708999633789\n",
      "batch_140: train_l:0.39632463391791, train_accuracy:0.8538065159574468, time_count:0.004319906234741211\n",
      "batch_150: train_l:0.39341103635876384, train_accuracy:0.855442880794702, time_count:0.004853010177612305\n",
      "batch_160: train_l:0.39178299052374704, train_accuracy:0.8559297360248447, time_count:0.0046617984771728516\n",
      "batch_170: train_l:0.39081431777156583, train_accuracy:0.85640533625731, time_count:0.005306243896484375\n",
      "batch_180: train_l:0.3916631510573856, train_accuracy:0.8560946132596685, time_count:0.004854679107666016\n",
      "batch_190: train_l:0.390497216067389, train_accuracy:0.8567162958115183, time_count:0.004445314407348633\n",
      "batch_200: train_l:0.39033737467296087, train_accuracy:0.8564404539800995, time_count:0.0047681331634521484\n",
      "batch_210: train_l:0.38984888636670406, train_accuracy:0.8566350710900474, time_count:0.0051004886627197266\n",
      "batch_220: train_l:0.3895470632147465, train_accuracy:0.8566353223981901, time_count:0.004216670989990234\n",
      "batch_230: train_l:0.38998156863373595, train_accuracy:0.856635551948052, time_count:0.004407405853271484\n",
      "================================\n",
      "epoch_6: test_acc:0.8316\n",
      "================================\n",
      "batch_0: train_l:0.3401327431201935, train_accuracy:0.88671875, time_count:0.005956888198852539\n",
      "batch_10: train_l:0.39201477711850946, train_accuracy:0.8483664772727273, time_count:0.004450321197509766\n",
      "batch_20: train_l:0.3825835174038297, train_accuracy:0.85546875, time_count:0.004996538162231445\n",
      "batch_30: train_l:0.36435457391123616, train_accuracy:0.8636592741935484, time_count:0.0049397945404052734\n",
      "batch_40: train_l:0.37239246688238004, train_accuracy:0.8592797256097561, time_count:0.005040645599365234\n",
      "batch_50: train_l:0.37009458623680414, train_accuracy:0.8592218137254902, time_count:0.006160736083984375\n",
      "batch_60: train_l:0.378414439373329, train_accuracy:0.8579021516393442, time_count:0.00500035285949707\n",
      "batch_70: train_l:0.3729866864815564, train_accuracy:0.8611355633802817, time_count:0.004881381988525391\n",
      "batch_80: train_l:0.3746254105626801, train_accuracy:0.8614486882716049, time_count:0.004734992980957031\n",
      "batch_90: train_l:0.37743878528312014, train_accuracy:0.8602335164835165, time_count:0.0043544769287109375\n",
      "batch_100: train_l:0.3772329735283804, train_accuracy:0.8601871905940595, time_count:0.004353761672973633\n",
      "batch_110: train_l:0.3770776396399146, train_accuracy:0.8603603603603603, time_count:0.004834651947021484\n",
      "batch_120: train_l:0.3764304895538929, train_accuracy:0.8607631714876033, time_count:0.004697084426879883\n",
      "batch_130: train_l:0.3747871415760681, train_accuracy:0.8615219465648855, time_count:0.004813194274902344\n",
      "batch_140: train_l:0.37301671674065556, train_accuracy:0.8622007978723404, time_count:0.005062103271484375\n",
      "batch_150: train_l:0.3750599583253166, train_accuracy:0.8613927980132451, time_count:0.00426936149597168\n",
      "batch_160: train_l:0.37622776192537744, train_accuracy:0.8610976319875776, time_count:0.0043811798095703125\n",
      "batch_170: train_l:0.3760126791676583, train_accuracy:0.8614994517543859, time_count:0.004229307174682617\n",
      "batch_180: train_l:0.37524277753922164, train_accuracy:0.8618352900552486, time_count:0.0045621395111083984\n",
      "batch_190: train_l:0.3729829714092285, train_accuracy:0.8628313154450262, time_count:0.004557609558105469\n",
      "batch_200: train_l:0.37361508630104917, train_accuracy:0.8627759639303483, time_count:0.005294084548950195\n",
      "batch_210: train_l:0.3734863227436328, train_accuracy:0.8628184241706162, time_count:0.005139589309692383\n",
      "batch_220: train_l:0.373118305974956, train_accuracy:0.8630868212669683, time_count:0.004884481430053711\n",
      "batch_230: train_l:0.37190683379575806, train_accuracy:0.8636532738095238, time_count:0.00420832633972168\n",
      "================================\n",
      "epoch_7: test_acc:0.859\n",
      "================================\n",
      "batch_0: train_l:0.3569350242614746, train_accuracy:0.84375, time_count:0.006133556365966797\n",
      "batch_10: train_l:0.3501844677058133, train_accuracy:0.8696732954545454, time_count:0.004471302032470703\n",
      "batch_20: train_l:0.3550345855099814, train_accuracy:0.8677455357142857, time_count:0.0053136348724365234\n",
      "batch_30: train_l:0.35303458859843595, train_accuracy:0.8719758064516129, time_count:0.004300117492675781\n",
      "batch_40: train_l:0.3574641950246764, train_accuracy:0.8705221036585366, time_count:0.005028486251831055\n",
      "batch_50: train_l:0.35774630425023096, train_accuracy:0.8700214460784313, time_count:0.004370689392089844\n",
      "batch_60: train_l:0.35935347002060686, train_accuracy:0.8691086065573771, time_count:0.0056684017181396484\n",
      "batch_70: train_l:0.35664787888526917, train_accuracy:0.8693331866197183, time_count:0.005499124526977539\n",
      "batch_80: train_l:0.3569162760251834, train_accuracy:0.8682484567901234, time_count:0.004899501800537109\n",
      "batch_90: train_l:0.3557669120830494, train_accuracy:0.8692908653846154, time_count:0.005098104476928711\n",
      "batch_100: train_l:0.35626983731099876, train_accuracy:0.8698561262376238, time_count:0.004380464553833008\n",
      "batch_110: train_l:0.36081460547876787, train_accuracy:0.8678913288288288, time_count:0.00528407096862793\n",
      "batch_120: train_l:0.36009973509252563, train_accuracy:0.8678977272727273, time_count:0.004721879959106445\n",
      "batch_130: train_l:0.36063825674639405, train_accuracy:0.8680522423664122, time_count:0.005343198776245117\n",
      "batch_140: train_l:0.35977006951967877, train_accuracy:0.8684618794326241, time_count:0.0044231414794921875\n",
      "batch_150: train_l:0.36099708632917593, train_accuracy:0.8680670529801324, time_count:0.005171537399291992\n",
      "batch_160: train_l:0.35987091268071475, train_accuracy:0.8684976708074534, time_count:0.0051250457763671875\n",
      "batch_170: train_l:0.35937390899100496, train_accuracy:0.8684438961988304, time_count:0.005271196365356445\n",
      "batch_180: train_l:0.35801137629793495, train_accuracy:0.8686982044198895, time_count:0.004474639892578125\n",
      "batch_190: train_l:0.35647127999685196, train_accuracy:0.8693144633507853, time_count:0.005378246307373047\n",
      "batch_200: train_l:0.3559793807677369, train_accuracy:0.8697916666666666, time_count:0.005187273025512695\n",
      "batch_210: train_l:0.35593670507742897, train_accuracy:0.8697978376777251, time_count:0.004656076431274414\n",
      "batch_220: train_l:0.35629991883605855, train_accuracy:0.8697150735294118, time_count:0.00460505485534668\n",
      "batch_230: train_l:0.3560566200322403, train_accuracy:0.8695041937229437, time_count:0.004507780075073242\n",
      "================================\n",
      "epoch_8: test_acc:0.8006\n",
      "================================\n",
      "batch_0: train_l:0.43160751461982727, train_accuracy:0.8046875, time_count:0.006400346755981445\n",
      "batch_10: train_l:0.347370827739889, train_accuracy:0.8650568181818182, time_count:0.005225419998168945\n",
      "batch_20: train_l:0.36033072358085994, train_accuracy:0.8608630952380952, time_count:0.005441427230834961\n",
      "batch_30: train_l:0.3717616383106478, train_accuracy:0.8576108870967742, time_count:0.006008148193359375\n",
      "batch_40: train_l:0.3623246332494224, train_accuracy:0.8620426829268293, time_count:0.006013154983520508\n",
      "batch_50: train_l:0.3528053047610264, train_accuracy:0.8655790441176471, time_count:0.0050313472747802734\n",
      "batch_60: train_l:0.3489796944328996, train_accuracy:0.8675717213114754, time_count:0.0045375823974609375\n",
      "batch_70: train_l:0.3537619877868975, train_accuracy:0.8664722711267606, time_count:0.004495143890380859\n",
      "batch_80: train_l:0.3501470697882735, train_accuracy:0.8680555555555556, time_count:0.004511117935180664\n",
      "batch_90: train_l:0.34839370175377354, train_accuracy:0.8698918269230769, time_count:0.005469083786010742\n",
      "batch_100: train_l:0.34705790287197225, train_accuracy:0.8703202351485149, time_count:0.004895210266113281\n",
      "batch_110: train_l:0.3448582160043287, train_accuracy:0.8710585585585585, time_count:0.004545688629150391\n",
      "batch_120: train_l:0.3437505393974052, train_accuracy:0.8713842975206612, time_count:0.0056514739990234375\n",
      "batch_130: train_l:0.34238768124398383, train_accuracy:0.8721374045801527, time_count:0.00587773323059082\n",
      "batch_140: train_l:0.3433625613544004, train_accuracy:0.8719525709219859, time_count:0.0062046051025390625\n",
      "batch_150: train_l:0.344601325246672, train_accuracy:0.8712489652317881, time_count:0.005077838897705078\n",
      "batch_160: train_l:0.3439352790021008, train_accuracy:0.8718216226708074, time_count:0.006880760192871094\n",
      "batch_170: train_l:0.34240456352456966, train_accuracy:0.8729669225146199, time_count:0.0063266754150390625\n",
      "batch_180: train_l:0.34265754911122404, train_accuracy:0.8729713397790055, time_count:0.006306171417236328\n",
      "batch_190: train_l:0.3413406459136783, train_accuracy:0.8734661321989529, time_count:0.0059201717376708984\n",
      "batch_200: train_l:0.3404109930221121, train_accuracy:0.8736201803482587, time_count:0.006577968597412109\n",
      "batch_210: train_l:0.3402698657241478, train_accuracy:0.8737966528436019, time_count:0.006269216537475586\n",
      "batch_220: train_l:0.3404283357691441, train_accuracy:0.8737097002262444, time_count:0.004751443862915039\n",
      "batch_230: train_l:0.33883697407328206, train_accuracy:0.8743574134199135, time_count:0.00446319580078125\n",
      "================================\n",
      "epoch_9: test_acc:0.8637\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "# Lenet with BatchNormal in Conv\n",
    "# LeNet\n",
    "# input: nx1x28x28\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import load_data_fashion_mnist\n",
    "from d2l import train_ch6_gpu\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2),nn.BatchNorm2d(6), nn.Sigmoid(),  # nx6x28x28\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),  # nx6x14x14\n",
    "    nn.Conv2d(6, 16, kernel_size=5),nn.BatchNorm2d(16), nn.Sigmoid(),  # nx16x10x10\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),  # nx16x5x5\n",
    "    nn.Flatten(),  # nx400\n",
    "    #  full connection block\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")\n",
    "\n",
    "X = torch.rand((1,1,28,28),dtype=torch.float32)\n",
    "\n",
    "net(X)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t\\t',X.shape)\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "lr, num_epochs = 0.9, 10\n",
    "train_ch6_gpu(net,train_iter=train_iter,test_iter=test_iter,num_epochs=num_epochs,lr=lr,device='cuda:0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t\t torch.Size([256, 6, 28, 28])\n",
      "BatchNorm2d output shape: \t\t torch.Size([256, 6, 28, 28])\n",
      "Sigmoid output shape: \t\t torch.Size([256, 6, 28, 28])\n",
      "AvgPool2d output shape: \t\t torch.Size([256, 6, 14, 14])\n",
      "Conv2d output shape: \t\t torch.Size([256, 16, 10, 10])\n",
      "BatchNorm2d output shape: \t\t torch.Size([256, 16, 10, 10])\n",
      "Sigmoid output shape: \t\t torch.Size([256, 16, 10, 10])\n",
      "AvgPool2d output shape: \t\t torch.Size([256, 16, 5, 5])\n",
      "Flatten output shape: \t\t torch.Size([256, 400])\n",
      "Linear output shape: \t\t torch.Size([256, 120])\n",
      "BatchNorm1d output shape: \t\t torch.Size([256, 120])\n",
      "Sigmoid output shape: \t\t torch.Size([256, 120])\n",
      "Linear output shape: \t\t torch.Size([256, 84])\n",
      "BatchNorm1d output shape: \t\t torch.Size([256, 84])\n",
      "Sigmoid output shape: \t\t torch.Size([256, 84])\n",
      "Linear output shape: \t\t torch.Size([256, 10])\n",
      "net will be trained on cuda:0\n",
      "batch_0: train_l:2.6358017921447754, train_accuracy:0.0390625, time_count:0.007390022277832031\n",
      "batch_10: train_l:1.8872987140308728, train_accuracy:0.3721590909090909, time_count:0.00776982307434082\n",
      "batch_20: train_l:1.533692615372794, train_accuracy:0.484375, time_count:0.005683422088623047\n",
      "batch_30: train_l:1.3856939538832633, train_accuracy:0.5225554435483871, time_count:0.006266355514526367\n",
      "batch_40: train_l:1.244451995302991, train_accuracy:0.5659298780487805, time_count:0.006897449493408203\n",
      "batch_50: train_l:1.1464036247309517, train_accuracy:0.5994944852941176, time_count:0.0050394535064697266\n",
      "batch_60: train_l:1.073984672788714, train_accuracy:0.6228227459016393, time_count:0.006247520446777344\n",
      "batch_70: train_l:1.0212692173433975, train_accuracy:0.6404599471830986, time_count:0.005944252014160156\n",
      "batch_80: train_l:0.9798733901094507, train_accuracy:0.6535011574074074, time_count:0.005861520767211914\n",
      "batch_90: train_l:0.9432471427288684, train_accuracy:0.6663804945054945, time_count:0.0053827762603759766\n",
      "batch_100: train_l:0.9081616578715863, train_accuracy:0.6779470915841584, time_count:0.005216836929321289\n",
      "batch_110: train_l:0.8806857762036023, train_accuracy:0.6873592342342343, time_count:0.004607439041137695\n",
      "batch_120: train_l:0.8629540884790342, train_accuracy:0.6933755165289256, time_count:0.0047855377197265625\n",
      "batch_130: train_l:0.8442935622830428, train_accuracy:0.6992485687022901, time_count:0.0043790340423583984\n",
      "batch_140: train_l:0.8254308808357158, train_accuracy:0.7055906471631206, time_count:0.0042688846588134766\n",
      "batch_150: train_l:0.8083719800639626, train_accuracy:0.7117653145695364, time_count:0.004739284515380859\n",
      "batch_160: train_l:0.791398827333628, train_accuracy:0.7176096661490683, time_count:0.0044939517974853516\n",
      "batch_170: train_l:0.775026172748086, train_accuracy:0.7236842105263158, time_count:0.004915475845336914\n",
      "batch_180: train_l:0.7643688759092468, train_accuracy:0.7268430593922652, time_count:0.004969358444213867\n",
      "batch_190: train_l:0.7544118131642567, train_accuracy:0.7302233311518325, time_count:0.0050466060638427734\n",
      "batch_200: train_l:0.740931177020666, train_accuracy:0.7351912313432836, time_count:0.004801034927368164\n",
      "batch_210: train_l:0.7275781375819473, train_accuracy:0.739947422985782, time_count:0.004530668258666992\n",
      "batch_220: train_l:0.7199727598898011, train_accuracy:0.7429298642533937, time_count:0.004282236099243164\n",
      "batch_230: train_l:0.7105008936547613, train_accuracy:0.7463304924242424, time_count:0.004155397415161133\n",
      "================================\n",
      "epoch_0: test_acc:0.8212139423076923\n",
      "================================\n",
      "batch_0: train_l:0.4276126027107239, train_accuracy:0.85546875, time_count:0.007464885711669922\n",
      "batch_10: train_l:0.5011868666518818, train_accuracy:0.8107244318181818, time_count:0.010588645935058594\n",
      "batch_20: train_l:0.4984989733923049, train_accuracy:0.8149181547619048, time_count:0.005345821380615234\n",
      "batch_30: train_l:0.4925998487780171, train_accuracy:0.8182963709677419, time_count:0.00530695915222168\n",
      "batch_40: train_l:0.4843868235262429, train_accuracy:0.8224085365853658, time_count:0.005440950393676758\n",
      "batch_50: train_l:0.4809613514180277, train_accuracy:0.8242953431372549, time_count:0.007627725601196289\n",
      "batch_60: train_l:0.48299795047181554, train_accuracy:0.8222976434426229, time_count:0.0060617923736572266\n",
      "batch_70: train_l:0.4788504100181687, train_accuracy:0.8239986795774648, time_count:0.00525665283203125\n",
      "batch_80: train_l:0.47461648377371424, train_accuracy:0.8269193672839507, time_count:0.005944252014160156\n",
      "batch_90: train_l:0.47224579800616256, train_accuracy:0.8279962225274725, time_count:0.0042917728424072266\n",
      "batch_100: train_l:0.46847373512711854, train_accuracy:0.8304842202970297, time_count:0.00433039665222168\n",
      "batch_110: train_l:0.4659874635236757, train_accuracy:0.8312570382882883, time_count:0.00470280647277832\n",
      "batch_120: train_l:0.4632665591299041, train_accuracy:0.8325800619834711, time_count:0.0046253204345703125\n",
      "batch_130: train_l:0.46387923241571616, train_accuracy:0.8320908874045801, time_count:0.004862308502197266\n",
      "batch_140: train_l:0.46364227381158385, train_accuracy:0.8319204343971631, time_count:0.0055484771728515625\n",
      "batch_150: train_l:0.4612344740242358, train_accuracy:0.8325745033112583, time_count:0.005593061447143555\n",
      "batch_160: train_l:0.4599580042850897, train_accuracy:0.8327591226708074, time_count:0.005346775054931641\n",
      "batch_170: train_l:0.4607079147595411, train_accuracy:0.8321454678362573, time_count:0.005454540252685547\n",
      "batch_180: train_l:0.45861237170946534, train_accuracy:0.8330455801104972, time_count:0.005406856536865234\n",
      "batch_190: train_l:0.4561118976607997, train_accuracy:0.8341991164921466, time_count:0.0052890777587890625\n",
      "batch_200: train_l:0.45293967803912377, train_accuracy:0.8353156094527363, time_count:0.0050449371337890625\n",
      "batch_210: train_l:0.45057482191171694, train_accuracy:0.8363632997630331, time_count:0.0048580169677734375\n",
      "batch_220: train_l:0.4504074289787948, train_accuracy:0.8367328902714932, time_count:0.0053293704986572266\n",
      "batch_230: train_l:0.4496196409066518, train_accuracy:0.8370028409090909, time_count:0.0054473876953125\n",
      "================================\n",
      "epoch_1: test_acc:0.7762419871794872\n",
      "================================\n",
      "batch_0: train_l:0.4337630569934845, train_accuracy:0.875, time_count:0.00720977783203125\n",
      "batch_10: train_l:0.4098186194896698, train_accuracy:0.8494318181818182, time_count:0.00478816032409668\n",
      "batch_20: train_l:0.42449304319563363, train_accuracy:0.8448660714285714, time_count:0.004666805267333984\n",
      "batch_30: train_l:0.4225240224792111, train_accuracy:0.8481602822580645, time_count:0.004448413848876953\n",
      "batch_40: train_l:0.4186564447676263, train_accuracy:0.8501333841463414, time_count:0.005577802658081055\n",
      "batch_50: train_l:0.41963574611673166, train_accuracy:0.8491115196078431, time_count:0.006011486053466797\n",
      "batch_60: train_l:0.4143419551556228, train_accuracy:0.8504098360655737, time_count:0.0048215389251708984\n",
      "batch_70: train_l:0.4030380599515539, train_accuracy:0.8546985035211268, time_count:0.0056345462799072266\n",
      "batch_80: train_l:0.4001533970420743, train_accuracy:0.8561921296296297, time_count:0.0046787261962890625\n",
      "batch_90: train_l:0.4015426098645388, train_accuracy:0.8561126373626373, time_count:0.004849433898925781\n",
      "batch_100: train_l:0.39813502649269483, train_accuracy:0.8574412128712872, time_count:0.004678010940551758\n",
      "batch_110: train_l:0.39750390922701034, train_accuracy:0.8578617680180181, time_count:0.005446910858154297\n",
      "batch_120: train_l:0.39517707371514693, train_accuracy:0.8583096590909091, time_count:0.0057528018951416016\n",
      "batch_130: train_l:0.39385672493745355, train_accuracy:0.8585997137404581, time_count:0.0054700374603271484\n",
      "batch_140: train_l:0.3914627532164256, train_accuracy:0.8596520390070922, time_count:0.005651712417602539\n",
      "batch_150: train_l:0.39054624114604974, train_accuracy:0.8595560844370861, time_count:0.004909992218017578\n",
      "batch_160: train_l:0.3868659457064563, train_accuracy:0.8610733695652174, time_count:0.0052454471588134766\n",
      "batch_170: train_l:0.38563280147418644, train_accuracy:0.8618192616959064, time_count:0.0046727657318115234\n",
      "batch_180: train_l:0.3842559384377622, train_accuracy:0.8620942679558011, time_count:0.005743503570556641\n",
      "batch_190: train_l:0.38232984530364034, train_accuracy:0.8627086060209425, time_count:0.005988359451293945\n",
      "batch_200: train_l:0.38310619565977977, train_accuracy:0.8621346393034826, time_count:0.0049610137939453125\n",
      "batch_210: train_l:0.38032671653828914, train_accuracy:0.8631146327014217, time_count:0.005218505859375\n",
      "batch_220: train_l:0.38027472274875207, train_accuracy:0.8628570418552036, time_count:0.004627704620361328\n",
      "batch_230: train_l:0.3806666885361527, train_accuracy:0.862790854978355, time_count:0.0050907135009765625\n",
      "================================\n",
      "epoch_2: test_acc:0.856270032051282\n",
      "================================\n",
      "batch_0: train_l:0.42720070481300354, train_accuracy:0.87109375, time_count:0.007813692092895508\n",
      "batch_10: train_l:0.3241351314566352, train_accuracy:0.8838778409090909, time_count:0.005537986755371094\n",
      "batch_20: train_l:0.34057048459847766, train_accuracy:0.8770461309523809, time_count:0.005833148956298828\n",
      "batch_30: train_l:0.33926390688265523, train_accuracy:0.8765120967741935, time_count:0.005940675735473633\n",
      "batch_40: train_l:0.33871124539433456, train_accuracy:0.8769054878048781, time_count:0.005800724029541016\n",
      "batch_50: train_l:0.3349074630760679, train_accuracy:0.8782935049019608, time_count:0.005298614501953125\n",
      "batch_60: train_l:0.3336551362862352, train_accuracy:0.8792264344262295, time_count:0.006750345230102539\n",
      "batch_70: train_l:0.33515704538620694, train_accuracy:0.8784110915492958, time_count:0.00565648078918457\n",
      "batch_80: train_l:0.335839777265066, train_accuracy:0.8782310956790124, time_count:0.005686044692993164\n",
      "batch_90: train_l:0.3384144199745996, train_accuracy:0.8773179945054945, time_count:0.005824089050292969\n",
      "batch_100: train_l:0.3421466236952508, train_accuracy:0.8757735148514851, time_count:0.006559133529663086\n",
      "batch_110: train_l:0.34220643905369014, train_accuracy:0.8750351914414415, time_count:0.005396842956542969\n",
      "batch_120: train_l:0.3410563999710004, train_accuracy:0.8763236053719008, time_count:0.0059239864349365234\n",
      "batch_130: train_l:0.33977192992927463, train_accuracy:0.8771171278625954, time_count:0.006042957305908203\n",
      "batch_140: train_l:0.3368370351216472, train_accuracy:0.8780751329787234, time_count:0.005079507827758789\n",
      "batch_150: train_l:0.33554189568323806, train_accuracy:0.8782595198675497, time_count:0.005782127380371094\n",
      "batch_160: train_l:0.33805853544925313, train_accuracy:0.8775960791925466, time_count:0.0059397220611572266\n",
      "batch_170: train_l:0.3361869470069283, train_accuracy:0.8781752558479532, time_count:0.005609989166259766\n",
      "batch_180: train_l:0.33491959566898766, train_accuracy:0.8783019682320442, time_count:0.004931926727294922\n",
      "batch_190: train_l:0.33425679092943983, train_accuracy:0.8785381217277487, time_count:0.005147695541381836\n",
      "batch_200: train_l:0.3345092905694573, train_accuracy:0.8782843594527363, time_count:0.0065190792083740234\n",
      "batch_210: train_l:0.33509216927239116, train_accuracy:0.8780546504739336, time_count:0.005430698394775391\n",
      "batch_220: train_l:0.33477686203982493, train_accuracy:0.8781992364253394, time_count:0.0057413578033447266\n",
      "batch_230: train_l:0.33445191305953187, train_accuracy:0.8781114718614719, time_count:0.004703044891357422\n",
      "================================\n",
      "epoch_3: test_acc:0.8621794871794872\n",
      "================================\n",
      "batch_0: train_l:0.36565372347831726, train_accuracy:0.8984375, time_count:0.007430315017700195\n",
      "batch_10: train_l:0.3442324535413222, train_accuracy:0.8742897727272727, time_count:0.0069658756256103516\n",
      "batch_20: train_l:0.3347406671160743, train_accuracy:0.8764880952380952, time_count:0.005759477615356445\n",
      "batch_30: train_l:0.33514904879754587, train_accuracy:0.8767641129032258, time_count:0.005491971969604492\n",
      "batch_40: train_l:0.326573743325908, train_accuracy:0.8770007621951219, time_count:0.005416393280029297\n",
      "batch_50: train_l:0.3243822513842115, train_accuracy:0.8785232843137255, time_count:0.005022287368774414\n",
      "batch_60: train_l:0.3204837973977699, train_accuracy:0.879546618852459, time_count:0.005094289779663086\n",
      "batch_70: train_l:0.3198722802417379, train_accuracy:0.8798415492957746, time_count:0.005819559097290039\n",
      "batch_80: train_l:0.3184999928430275, train_accuracy:0.8804976851851852, time_count:0.005011081695556641\n",
      "batch_90: train_l:0.3156647950738341, train_accuracy:0.8821256868131868, time_count:0.005080223083496094\n",
      "batch_100: train_l:0.31703291789139854, train_accuracy:0.8822710396039604, time_count:0.00579071044921875\n",
      "batch_110: train_l:0.31718755466444, train_accuracy:0.8823198198198198, time_count:0.0058116912841796875\n",
      "batch_120: train_l:0.31676937319523046, train_accuracy:0.8823605371900827, time_count:0.005126237869262695\n",
      "batch_130: train_l:0.31670501316321714, train_accuracy:0.8821564885496184, time_count:0.00513768196105957\n",
      "batch_140: train_l:0.31556290314129903, train_accuracy:0.8829233156028369, time_count:0.005072832107543945\n",
      "batch_150: train_l:0.3148227698163481, train_accuracy:0.8828125, time_count:0.005604982376098633\n",
      "batch_160: train_l:0.31474510288756824, train_accuracy:0.8828125, time_count:0.006077766418457031\n",
      "batch_170: train_l:0.3148376569587585, train_accuracy:0.8825840643274854, time_count:0.00555109977722168\n",
      "batch_180: train_l:0.3147459699468718, train_accuracy:0.8825966850828729, time_count:0.00580596923828125\n",
      "batch_190: train_l:0.3147303662531039, train_accuracy:0.8827920484293194, time_count:0.00574493408203125\n",
      "batch_200: train_l:0.3138922430686097, train_accuracy:0.8833760883084577, time_count:0.005364418029785156\n",
      "batch_210: train_l:0.31311783307536517, train_accuracy:0.8837381516587678, time_count:0.004757881164550781\n",
      "batch_220: train_l:0.3124851931678763, train_accuracy:0.8842088518099548, time_count:0.0045926570892333984\n",
      "batch_230: train_l:0.3137028881094672, train_accuracy:0.8837763798701299, time_count:0.004686117172241211\n",
      "================================\n",
      "epoch_4: test_acc:0.8500600961538461\n",
      "================================\n",
      "batch_0: train_l:0.2978775203227997, train_accuracy:0.90625, time_count:0.006893634796142578\n",
      "batch_10: train_l:0.30030217495831574, train_accuracy:0.8877840909090909, time_count:0.00475621223449707\n",
      "batch_20: train_l:0.2936104394140698, train_accuracy:0.8896949404761905, time_count:0.0048618316650390625\n",
      "batch_30: train_l:0.28573270430487974, train_accuracy:0.8922631048387096, time_count:0.005502223968505859\n",
      "batch_40: train_l:0.291581466794014, train_accuracy:0.8919588414634146, time_count:0.005468130111694336\n",
      "batch_50: train_l:0.29000479450412825, train_accuracy:0.8910079656862745, time_count:0.005784749984741211\n",
      "batch_60: train_l:0.2940491772577411, train_accuracy:0.8904969262295082, time_count:0.006667375564575195\n",
      "batch_70: train_l:0.2929383864704992, train_accuracy:0.891450264084507, time_count:0.005596637725830078\n",
      "batch_80: train_l:0.2944649200380584, train_accuracy:0.8904320987654321, time_count:0.0058133602142333984\n",
      "batch_90: train_l:0.29212788271379997, train_accuracy:0.8913976648351648, time_count:0.005837917327880859\n",
      "batch_100: train_l:0.29552753992600017, train_accuracy:0.8896581064356436, time_count:0.0054187774658203125\n",
      "batch_110: train_l:0.2942729189589217, train_accuracy:0.8905194256756757, time_count:0.005906105041503906\n",
      "batch_120: train_l:0.29370606487447565, train_accuracy:0.8906895661157025, time_count:0.0053980350494384766\n",
      "batch_130: train_l:0.2928242118076514, train_accuracy:0.8911319179389313, time_count:0.005182027816772461\n",
      "batch_140: train_l:0.2938982904591459, train_accuracy:0.8907081117021277, time_count:0.0049381256103515625\n",
      "batch_150: train_l:0.29463829948807396, train_accuracy:0.8908060844370861, time_count:0.004967451095581055\n",
      "batch_160: train_l:0.29528221265869853, train_accuracy:0.8899456521739131, time_count:0.005515098571777344\n",
      "batch_170: train_l:0.2941416494156185, train_accuracy:0.8901909722222222, time_count:0.005307674407958984\n",
      "batch_180: train_l:0.2936170237828355, train_accuracy:0.8907329074585635, time_count:0.006230592727661133\n",
      "batch_190: train_l:0.2922884039385781, train_accuracy:0.8912794502617801, time_count:0.0048542022705078125\n",
      "batch_200: train_l:0.2920817140471283, train_accuracy:0.8916550062189055, time_count:0.005112171173095703\n",
      "batch_210: train_l:0.2917051645816785, train_accuracy:0.8917357819905213, time_count:0.00547480583190918\n",
      "batch_220: train_l:0.29155714472764216, train_accuracy:0.8920036764705882, time_count:0.005042076110839844\n",
      "batch_230: train_l:0.29173140021371635, train_accuracy:0.8917410714285714, time_count:0.0048639774322509766\n",
      "================================\n",
      "epoch_5: test_acc:0.8821113782051282\n",
      "================================\n",
      "batch_0: train_l:0.2148859053850174, train_accuracy:0.91015625, time_count:0.008895397186279297\n",
      "batch_10: train_l:0.26479211991483514, train_accuracy:0.9044744318181818, time_count:0.005663156509399414\n",
      "batch_20: train_l:0.26746852624984013, train_accuracy:0.9006696428571429, time_count:0.006376028060913086\n",
      "batch_30: train_l:0.2697863583603213, train_accuracy:0.8999495967741935, time_count:0.00589299201965332\n",
      "batch_40: train_l:0.2799578036476926, train_accuracy:0.8962461890243902, time_count:0.0065517425537109375\n",
      "batch_50: train_l:0.28095001332900105, train_accuracy:0.8955269607843137, time_count:0.005728244781494141\n",
      "batch_60: train_l:0.27789851558990164, train_accuracy:0.8979252049180327, time_count:0.006331205368041992\n",
      "batch_70: train_l:0.27402803847487545, train_accuracy:0.8992077464788732, time_count:0.005925416946411133\n",
      "batch_80: train_l:0.27777781383490857, train_accuracy:0.8982928240740741, time_count:0.005182027816772461\n",
      "batch_90: train_l:0.2759812362901457, train_accuracy:0.8983087225274725, time_count:0.005884647369384766\n",
      "batch_100: train_l:0.2756468315820883, train_accuracy:0.8982441212871287, time_count:0.005614757537841797\n",
      "batch_110: train_l:0.27505374330658094, train_accuracy:0.8980855855855856, time_count:0.005230903625488281\n",
      "batch_120: train_l:0.27683203759764835, train_accuracy:0.896823347107438, time_count:0.0055389404296875\n",
      "batch_130: train_l:0.27931909536132377, train_accuracy:0.8955749045801527, time_count:0.00507664680480957\n",
      "batch_140: train_l:0.2815060690573767, train_accuracy:0.8948082890070922, time_count:0.0056171417236328125\n",
      "batch_150: train_l:0.2830440691172682, train_accuracy:0.8940914735099338, time_count:0.0050470829010009766\n",
      "batch_160: train_l:0.28260291705590596, train_accuracy:0.8945069875776398, time_count:0.0050127506256103516\n",
      "batch_170: train_l:0.28217380594091807, train_accuracy:0.894828216374269, time_count:0.005105495452880859\n",
      "batch_180: train_l:0.2820007552428799, train_accuracy:0.8949197168508287, time_count:0.00507354736328125\n",
      "batch_190: train_l:0.2804351292979655, train_accuracy:0.8955947316753927, time_count:0.0051648616790771484\n",
      "batch_200: train_l:0.28107650874562523, train_accuracy:0.8958722014925373, time_count:0.005331993103027344\n",
      "batch_210: train_l:0.2817376130282596, train_accuracy:0.8958271623222749, time_count:0.006115436553955078\n",
      "batch_220: train_l:0.28165902008568, train_accuracy:0.8957154977375565, time_count:0.004993438720703125\n",
      "batch_230: train_l:0.2813201735675077, train_accuracy:0.8957318722943723, time_count:0.004744291305541992\n",
      "================================\n",
      "epoch_6: test_acc:0.8490584935897436\n",
      "================================\n",
      "batch_0: train_l:0.2113114446401596, train_accuracy:0.9140625, time_count:0.006876468658447266\n",
      "batch_10: train_l:0.251286196437749, train_accuracy:0.90625, time_count:0.005226612091064453\n",
      "batch_20: train_l:0.25873924224149614, train_accuracy:0.9036458333333334, time_count:0.005991935729980469\n",
      "batch_30: train_l:0.2619820520762474, train_accuracy:0.9018397177419355, time_count:0.005788564682006836\n",
      "batch_40: train_l:0.26425559673367477, train_accuracy:0.9022484756097561, time_count:0.004969120025634766\n",
      "batch_50: train_l:0.2645922852497475, train_accuracy:0.9022671568627451, time_count:0.004890918731689453\n",
      "batch_60: train_l:0.26465561301981816, train_accuracy:0.9025998975409836, time_count:0.0060176849365234375\n",
      "batch_70: train_l:0.2626411180261155, train_accuracy:0.9033340669014085, time_count:0.00560450553894043\n",
      "batch_80: train_l:0.2624528584656892, train_accuracy:0.9037905092592593, time_count:0.0061113834381103516\n",
      "batch_90: train_l:0.2644481857071866, train_accuracy:0.9032022664835165, time_count:0.005769968032836914\n",
      "batch_100: train_l:0.26379868152117963, train_accuracy:0.903542698019802, time_count:0.004801750183105469\n",
      "batch_110: train_l:0.2637150188287099, train_accuracy:0.9036458333333334, time_count:0.0053632259368896484\n",
      "batch_120: train_l:0.2645838671971944, train_accuracy:0.9029571280991735, time_count:0.0053958892822265625\n",
      "batch_130: train_l:0.2637453564933238, train_accuracy:0.9033277671755725, time_count:0.005037069320678711\n",
      "batch_140: train_l:0.2653592936958827, train_accuracy:0.9030363475177305, time_count:0.006727695465087891\n",
      "batch_150: train_l:0.26587081656156, train_accuracy:0.9027059188741722, time_count:0.0059850215911865234\n",
      "batch_160: train_l:0.266050023599441, train_accuracy:0.9027076863354038, time_count:0.0066242218017578125\n",
      "batch_170: train_l:0.2671215927217439, train_accuracy:0.9025493421052632, time_count:0.006025552749633789\n",
      "batch_180: train_l:0.26657284096459655, train_accuracy:0.9027322168508287, time_count:0.007348537445068359\n",
      "batch_190: train_l:0.2670790031162232, train_accuracy:0.9022823952879581, time_count:0.006082057952880859\n",
      "batch_200: train_l:0.2663180245392358, train_accuracy:0.902402052238806, time_count:0.007082223892211914\n",
      "batch_210: train_l:0.2653985259374736, train_accuracy:0.90286211492891, time_count:0.0051157474517822266\n",
      "batch_220: train_l:0.26598029816312485, train_accuracy:0.9023967760180995, time_count:0.005255699157714844\n",
      "batch_230: train_l:0.2649252134742159, train_accuracy:0.9028510551948052, time_count:0.004988670349121094\n",
      "================================\n",
      "epoch_7: test_acc:0.8760016025641025\n",
      "================================\n",
      "batch_0: train_l:0.284385085105896, train_accuracy:0.90234375, time_count:0.006934165954589844\n",
      "batch_10: train_l:0.23862045732411472, train_accuracy:0.9140625, time_count:0.004885435104370117\n",
      "batch_20: train_l:0.2557706023965563, train_accuracy:0.9073660714285714, time_count:0.006013393402099609\n",
      "batch_30: train_l:0.2623798078106296, train_accuracy:0.9044858870967742, time_count:0.005388021469116211\n",
      "batch_40: train_l:0.26103897974258516, train_accuracy:0.9049161585365854, time_count:0.0051915645599365234\n",
      "batch_50: train_l:0.26101938153014465, train_accuracy:0.9038756127450981, time_count:0.005327701568603516\n",
      "batch_60: train_l:0.2592776583843544, train_accuracy:0.9039446721311475, time_count:0.0048236846923828125\n",
      "batch_70: train_l:0.25458461256094383, train_accuracy:0.9058648767605634, time_count:0.0051097869873046875\n",
      "batch_80: train_l:0.2529290066457089, train_accuracy:0.9071180555555556, time_count:0.0052089691162109375\n",
      "batch_90: train_l:0.25644741035424745, train_accuracy:0.9048763736263736, time_count:0.005051374435424805\n",
      "batch_100: train_l:0.25595971366556564, train_accuracy:0.9049350247524752, time_count:0.005674123764038086\n",
      "batch_110: train_l:0.25652557222155836, train_accuracy:0.9045960022522522, time_count:0.0051686763763427734\n",
      "batch_120: train_l:0.2552446360923042, train_accuracy:0.9050232438016529, time_count:0.005907773971557617\n",
      "batch_130: train_l:0.25490258804714405, train_accuracy:0.9049081583969466, time_count:0.00693964958190918\n",
      "batch_140: train_l:0.2550627550123431, train_accuracy:0.9046985815602837, time_count:0.005713701248168945\n",
      "batch_150: train_l:0.2568825471480161, train_accuracy:0.9037665562913907, time_count:0.006237506866455078\n",
      "batch_160: train_l:0.25764464785963853, train_accuracy:0.9037994953416149, time_count:0.005797624588012695\n",
      "batch_170: train_l:0.25751579382963347, train_accuracy:0.9039656432748538, time_count:0.0051462650299072266\n",
      "batch_180: train_l:0.2581469522819993, train_accuracy:0.9036386395027625, time_count:0.005597829818725586\n",
      "batch_190: train_l:0.25725333158570435, train_accuracy:0.9040412303664922, time_count:0.005809783935546875\n",
      "batch_200: train_l:0.25682585534468216, train_accuracy:0.904248289800995, time_count:0.006011962890625\n",
      "batch_210: train_l:0.25579260706336576, train_accuracy:0.9045468009478673, time_count:0.005170345306396484\n",
      "batch_220: train_l:0.2549029542849614, train_accuracy:0.9050480769230769, time_count:0.004762887954711914\n",
      "batch_230: train_l:0.25504235381429846, train_accuracy:0.9050493777056277, time_count:0.0047152042388916016\n",
      "================================\n",
      "epoch_8: test_acc:0.8586738782051282\n",
      "================================\n",
      "batch_0: train_l:0.2490329146385193, train_accuracy:0.92578125, time_count:0.007459878921508789\n",
      "batch_10: train_l:0.24233428050171246, train_accuracy:0.9073153409090909, time_count:0.004808664321899414\n",
      "batch_20: train_l:0.25527034558001016, train_accuracy:0.9017857142857143, time_count:0.006581306457519531\n",
      "batch_30: train_l:0.24703160649345768, train_accuracy:0.9056199596774194, time_count:0.006296396255493164\n",
      "batch_40: train_l:0.2442034926356339, train_accuracy:0.9063452743902439, time_count:0.0055084228515625\n",
      "batch_50: train_l:0.24430506135903152, train_accuracy:0.9078584558823529, time_count:0.005282402038574219\n",
      "batch_60: train_l:0.24209614611062846, train_accuracy:0.9088114754098361, time_count:0.005552053451538086\n",
      "batch_70: train_l:0.2451880588917665, train_accuracy:0.9072953345070423, time_count:0.005769491195678711\n",
      "batch_80: train_l:0.24418457790657325, train_accuracy:0.9074074074074074, time_count:0.006104469299316406\n",
      "batch_90: train_l:0.24419162086733096, train_accuracy:0.9077953296703297, time_count:0.005224704742431641\n",
      "batch_100: train_l:0.24339637514388207, train_accuracy:0.907294245049505, time_count:0.005030393600463867\n",
      "batch_110: train_l:0.2441208092747508, train_accuracy:0.907200168918919, time_count:0.006212949752807617\n",
      "batch_120: train_l:0.24508924277360775, train_accuracy:0.9073476239669421, time_count:0.005072116851806641\n",
      "batch_130: train_l:0.24448231454113967, train_accuracy:0.9076514790076335, time_count:0.006563663482666016\n",
      "batch_140: train_l:0.24472630837707654, train_accuracy:0.9079953457446809, time_count:0.0050852298736572266\n",
      "batch_150: train_l:0.2461284754292065, train_accuracy:0.9074141142384106, time_count:0.0056002140045166016\n",
      "batch_160: train_l:0.24740057489516573, train_accuracy:0.9069778726708074, time_count:0.005791425704956055\n",
      "batch_170: train_l:0.24692084043346652, train_accuracy:0.9073921783625731, time_count:0.005674123764038086\n",
      "batch_180: train_l:0.24702759564581497, train_accuracy:0.9072427486187845, time_count:0.0058002471923828125\n",
      "batch_190: train_l:0.2469244785021737, train_accuracy:0.907129417539267, time_count:0.00579380989074707\n",
      "batch_200: train_l:0.2461845001474542, train_accuracy:0.9075326492537313, time_count:0.00606536865234375\n",
      "batch_210: train_l:0.24699810069601683, train_accuracy:0.9071386255924171, time_count:0.005393028259277344\n",
      "batch_220: train_l:0.24752241797846367, train_accuracy:0.9072751696832579, time_count:0.005532979965209961\n",
      "batch_230: train_l:0.2468904590322858, train_accuracy:0.9075859036796536, time_count:0.0048596858978271484\n",
      "================================\n",
      "epoch_9: test_acc:0.8464543269230769\n",
      "================================\n",
      "batch_0: train_l:0.30342453718185425, train_accuracy:0.890625, time_count:0.005841493606567383\n",
      "batch_10: train_l:0.24163886362856085, train_accuracy:0.91015625, time_count:0.005706310272216797\n",
      "batch_20: train_l:0.2265193157252811, train_accuracy:0.9168526785714286, time_count:0.0056803226470947266\n",
      "batch_30: train_l:0.23363175267173397, train_accuracy:0.9140625, time_count:0.005170345306396484\n",
      "batch_40: train_l:0.23536739770959064, train_accuracy:0.9126333841463414, time_count:0.004970550537109375\n",
      "batch_50: train_l:0.23346726158085992, train_accuracy:0.9135263480392157, time_count:0.005607128143310547\n",
      "batch_60: train_l:0.23839875176304676, train_accuracy:0.9118212090163934, time_count:0.005793571472167969\n",
      "batch_70: train_l:0.24209595671002293, train_accuracy:0.9113116197183099, time_count:0.006072044372558594\n",
      "batch_80: train_l:0.2417232859649776, train_accuracy:0.9103491512345679, time_count:0.005571842193603516\n",
      "batch_90: train_l:0.23808995216757387, train_accuracy:0.9117445054945055, time_count:0.0059070587158203125\n",
      "batch_100: train_l:0.23460337180312318, train_accuracy:0.9134436881188119, time_count:0.004954099655151367\n",
      "batch_110: train_l:0.23303841833058778, train_accuracy:0.9138161599099099, time_count:0.005197048187255859\n",
      "batch_120: train_l:0.2329412578058637, train_accuracy:0.9140625, time_count:0.00600886344909668\n",
      "batch_130: train_l:0.23324524025425655, train_accuracy:0.9137643129770993, time_count:0.006487846374511719\n",
      "batch_140: train_l:0.23349298610754893, train_accuracy:0.9136746453900709, time_count:0.005057811737060547\n",
      "batch_150: train_l:0.23320474776605896, train_accuracy:0.9137779387417219, time_count:0.0051653385162353516\n",
      "batch_160: train_l:0.233280752664027, train_accuracy:0.9139411878881988, time_count:0.006101846694946289\n",
      "batch_170: train_l:0.23289567990261212, train_accuracy:0.9139939692982456, time_count:0.006407976150512695\n",
      "batch_180: train_l:0.23315760822585932, train_accuracy:0.9136740331491713, time_count:0.005475282669067383\n",
      "batch_190: train_l:0.23412163001704592, train_accuracy:0.9135512107329843, time_count:0.005086183547973633\n",
      "batch_200: train_l:0.23417571557695, train_accuracy:0.9134406094527363, time_count:0.0058515071868896484\n",
      "batch_210: train_l:0.2346255048332621, train_accuracy:0.9137662914691943, time_count:0.005188465118408203\n",
      "batch_220: train_l:0.23466760682034815, train_accuracy:0.9138680712669683, time_count:0.005296468734741211\n",
      "batch_230: train_l:0.23488118335024102, train_accuracy:0.9139948593073594, time_count:0.004716634750366211\n",
      "================================\n",
      "epoch_10: test_acc:0.8850160256410257\n",
      "================================\n",
      "batch_0: train_l:0.19895786046981812, train_accuracy:0.91015625, time_count:0.006404399871826172\n",
      "batch_10: train_l:0.21601571278138595, train_accuracy:0.9190340909090909, time_count:0.005838155746459961\n",
      "batch_20: train_l:0.22156497552281335, train_accuracy:0.9153645833333334, time_count:0.005013942718505859\n",
      "batch_30: train_l:0.22239680588245392, train_accuracy:0.9145665322580645, time_count:0.0057871341705322266\n",
      "batch_40: train_l:0.22066081842271293, train_accuracy:0.9165396341463414, time_count:0.0055925846099853516\n",
      "batch_50: train_l:0.22005067648840884, train_accuracy:0.9172794117647058, time_count:0.005215883255004883\n",
      "batch_60: train_l:0.2225159003597791, train_accuracy:0.9154713114754098, time_count:0.006154060363769531\n",
      "batch_70: train_l:0.2201990934324936, train_accuracy:0.9176386443661971, time_count:0.00548863410949707\n",
      "batch_80: train_l:0.2209159991255513, train_accuracy:0.9178722993827161, time_count:0.00496983528137207\n",
      "batch_90: train_l:0.22267512027378922, train_accuracy:0.9174107142857143, time_count:0.005124330520629883\n",
      "batch_100: train_l:0.22519137865245933, train_accuracy:0.9160736386138614, time_count:0.005154132843017578\n",
      "batch_110: train_l:0.2244136632831247, train_accuracy:0.9159628378378378, time_count:0.005072355270385742\n",
      "batch_120: train_l:0.22562226616154032, train_accuracy:0.9157735020661157, time_count:0.005209207534790039\n",
      "batch_130: train_l:0.22466101400724803, train_accuracy:0.916030534351145, time_count:0.005140542984008789\n",
      "batch_140: train_l:0.22834547614374906, train_accuracy:0.9147828014184397, time_count:0.0050449371337890625\n",
      "batch_150: train_l:0.2295856231095775, train_accuracy:0.9142435844370861, time_count:0.005885601043701172\n",
      "batch_160: train_l:0.2293986561505691, train_accuracy:0.9141838121118012, time_count:0.006194591522216797\n",
      "batch_170: train_l:0.2297503489848466, train_accuracy:0.9142909356725146, time_count:0.0053768157958984375\n",
      "batch_180: train_l:0.2298251352586799, train_accuracy:0.9142998964088398, time_count:0.005808830261230469\n",
      "batch_190: train_l:0.2299265856050072, train_accuracy:0.9142056609947644, time_count:0.006116151809692383\n",
      "batch_200: train_l:0.2304132091465281, train_accuracy:0.9139070273631841, time_count:0.0057446956634521484\n",
      "batch_210: train_l:0.2306461079284478, train_accuracy:0.913858856635071, time_count:0.00668025016784668\n",
      "batch_220: train_l:0.22941081091019902, train_accuracy:0.9143806561085973, time_count:0.006037473678588867\n",
      "batch_230: train_l:0.22952927771584813, train_accuracy:0.9143668831168831, time_count:0.004935026168823242\n",
      "================================\n",
      "epoch_11: test_acc:0.8792067307692307\n",
      "================================\n",
      "batch_0: train_l:0.14266841113567352, train_accuracy:0.95703125, time_count:0.0073947906494140625\n",
      "batch_10: train_l:0.2116075483235446, train_accuracy:0.9268465909090909, time_count:0.005233049392700195\n",
      "batch_20: train_l:0.20940981947240375, train_accuracy:0.9259672619047619, time_count:0.0057790279388427734\n",
      "batch_30: train_l:0.2178379378972515, train_accuracy:0.9220010080645161, time_count:0.005293369293212891\n",
      "batch_40: train_l:0.22068657126368546, train_accuracy:0.9200647865853658, time_count:0.006234884262084961\n",
      "batch_50: train_l:0.22501692497262768, train_accuracy:0.9169730392156863, time_count:0.006072044372558594\n",
      "batch_60: train_l:0.2220733756901788, train_accuracy:0.9190573770491803, time_count:0.005025625228881836\n",
      "batch_70: train_l:0.22013752624182634, train_accuracy:0.9198943661971831, time_count:0.005757331848144531\n",
      "batch_80: train_l:0.22026089348910768, train_accuracy:0.9195119598765432, time_count:0.006749391555786133\n",
      "batch_90: train_l:0.22090631428655688, train_accuracy:0.9191277472527473, time_count:0.005912303924560547\n",
      "batch_100: train_l:0.22112223402698442, train_accuracy:0.9188196163366337, time_count:0.005410671234130859\n",
      "batch_110: train_l:0.21959640327337626, train_accuracy:0.9192004504504504, time_count:0.0065212249755859375\n",
      "batch_120: train_l:0.21994065844323024, train_accuracy:0.9187435433884298, time_count:0.0051212310791015625\n",
      "batch_130: train_l:0.2187356459730454, train_accuracy:0.9193105916030534, time_count:0.005288124084472656\n",
      "batch_140: train_l:0.21840886158723358, train_accuracy:0.9194647606382979, time_count:0.006085395812988281\n",
      "batch_150: train_l:0.2189242626657549, train_accuracy:0.9188483029801324, time_count:0.005360841751098633\n",
      "batch_160: train_l:0.21983529997538337, train_accuracy:0.9189877717391305, time_count:0.0051288604736328125\n",
      "batch_170: train_l:0.22091208807906212, train_accuracy:0.9187454312865497, time_count:0.006867408752441406\n",
      "batch_180: train_l:0.22193309681191628, train_accuracy:0.9181414019337016, time_count:0.005209684371948242\n",
      "batch_190: train_l:0.22056001744657286, train_accuracy:0.9186436518324608, time_count:0.005321979522705078\n",
      "batch_200: train_l:0.22030710692132882, train_accuracy:0.9188044154228856, time_count:0.005173444747924805\n",
      "batch_210: train_l:0.22091255559457987, train_accuracy:0.9186722452606635, time_count:0.005851030349731445\n",
      "batch_220: train_l:0.22049203515052795, train_accuracy:0.9189585690045249, time_count:0.0051538944244384766\n",
      "batch_230: train_l:0.22223872507547404, train_accuracy:0.918171672077922, time_count:0.004897356033325195\n",
      "================================\n",
      "epoch_12: test_acc:0.8889222756410257\n",
      "================================\n",
      "batch_0: train_l:0.2625923454761505, train_accuracy:0.890625, time_count:0.008347511291503906\n",
      "batch_10: train_l:0.22847478769042276, train_accuracy:0.9108664772727273, time_count:0.0049974918365478516\n",
      "batch_20: train_l:0.21203029581478663, train_accuracy:0.9196428571428571, time_count:0.005316972732543945\n",
      "batch_30: train_l:0.20939410069296438, train_accuracy:0.9206149193548387, time_count:0.006066799163818359\n",
      "batch_40: train_l:0.20744241410639228, train_accuracy:0.9207317073170732, time_count:0.005651950836181641\n",
      "batch_50: train_l:0.20478172892448948, train_accuracy:0.9217984068627451, time_count:0.005469560623168945\n",
      "batch_60: train_l:0.2059070895441243, train_accuracy:0.9218109631147541, time_count:0.005997180938720703\n",
      "batch_70: train_l:0.20931235291588474, train_accuracy:0.9208296654929577, time_count:0.006918191909790039\n",
      "batch_80: train_l:0.2094938944519302, train_accuracy:0.9207175925925926, time_count:0.005663394927978516\n",
      "batch_90: train_l:0.20893358955016503, train_accuracy:0.9214028159340659, time_count:0.005293130874633789\n",
      "batch_100: train_l:0.210809396192579, train_accuracy:0.9202506188118812, time_count:0.005268096923828125\n",
      "batch_110: train_l:0.21171517307693893, train_accuracy:0.9198338963963963, time_count:0.005818605422973633\n",
      "batch_120: train_l:0.2138477122980701, train_accuracy:0.9193892045454546, time_count:0.0056095123291015625\n",
      "batch_130: train_l:0.21333538792060533, train_accuracy:0.9197280534351145, time_count:0.005414724349975586\n",
      "batch_140: train_l:0.2124410925816137, train_accuracy:0.9200742464539007, time_count:0.005934715270996094\n",
      "batch_150: train_l:0.21259423498286317, train_accuracy:0.9199865480132451, time_count:0.005141258239746094\n",
      "batch_160: train_l:0.21263996803242227, train_accuracy:0.9204677795031055, time_count:0.005559206008911133\n",
      "batch_170: train_l:0.21436514448352725, train_accuracy:0.9200018274853801, time_count:0.005724668502807617\n",
      "batch_180: train_l:0.21415833643128201, train_accuracy:0.9202995511049724, time_count:0.005913496017456055\n",
      "batch_190: train_l:0.21332462865332658, train_accuracy:0.9204638416230366, time_count:0.005018711090087891\n",
      "batch_200: train_l:0.21318133612770346, train_accuracy:0.9206312189054726, time_count:0.0052623748779296875\n",
      "batch_210: train_l:0.21349746454948498, train_accuracy:0.9206161137440758, time_count:0.005800485610961914\n",
      "batch_220: train_l:0.2129760061588762, train_accuracy:0.9207968042986425, time_count:0.0055730342864990234\n",
      "batch_230: train_l:0.21265168352560562, train_accuracy:0.9208096590909091, time_count:0.004757881164550781\n",
      "================================\n",
      "epoch_13: test_acc:0.8774038461538461\n",
      "================================\n",
      "batch_0: train_l:0.19085349142551422, train_accuracy:0.93359375, time_count:0.007221698760986328\n",
      "batch_10: train_l:0.20534743639555844, train_accuracy:0.9211647727272727, time_count:0.00584101676940918\n",
      "batch_20: train_l:0.19627537755739122, train_accuracy:0.9295014880952381, time_count:0.005869150161743164\n",
      "batch_30: train_l:0.19687788044252702, train_accuracy:0.9311995967741935, time_count:0.004977226257324219\n",
      "batch_40: train_l:0.2004953113997855, train_accuracy:0.9297827743902439, time_count:0.0057604312896728516\n",
      "batch_50: train_l:0.20399880467676648, train_accuracy:0.9274662990196079, time_count:0.0052716732025146484\n",
      "batch_60: train_l:0.20338752768078788, train_accuracy:0.9268698770491803, time_count:0.0055119991302490234\n",
      "batch_70: train_l:0.20365781011715742, train_accuracy:0.9267715669014085, time_count:0.006078481674194336\n",
      "batch_80: train_l:0.2029782811432709, train_accuracy:0.9267939814814815, time_count:0.0061244964599609375\n",
      "batch_90: train_l:0.20497052486126238, train_accuracy:0.9256095467032966, time_count:0.005307912826538086\n",
      "batch_100: train_l:0.2075011668228867, train_accuracy:0.9240021658415841, time_count:0.005382061004638672\n",
      "batch_110: train_l:0.2066076955011299, train_accuracy:0.9240216779279279, time_count:0.005110740661621094\n",
      "batch_120: train_l:0.20610287588489942, train_accuracy:0.9239088326446281, time_count:0.005382061004638672\n",
      "batch_130: train_l:0.20797233078770966, train_accuracy:0.9231870229007634, time_count:0.0058746337890625\n",
      "batch_140: train_l:0.20736325463504657, train_accuracy:0.9234541223404256, time_count:0.0059359073638916016\n",
      "batch_150: train_l:0.2078850765694056, train_accuracy:0.9235047599337748, time_count:0.005164623260498047\n",
      "batch_160: train_l:0.20782456246222028, train_accuracy:0.9235976319875776, time_count:0.005418062210083008\n",
      "batch_170: train_l:0.20711356392729352, train_accuracy:0.9235654239766082, time_count:0.00570225715637207\n",
      "batch_180: train_l:0.2069918939751156, train_accuracy:0.9232993784530387, time_count:0.006542205810546875\n",
      "batch_190: train_l:0.20760454947411702, train_accuracy:0.9232657068062827, time_count:0.005045890808105469\n",
      "batch_200: train_l:0.20720737683239268, train_accuracy:0.9232353855721394, time_count:0.004996776580810547\n",
      "batch_210: train_l:0.20614530922959767, train_accuracy:0.923541172985782, time_count:0.005540370941162109\n",
      "batch_220: train_l:0.20726634366479935, train_accuracy:0.9229531957013575, time_count:0.005264997482299805\n",
      "batch_230: train_l:0.20800777476329307, train_accuracy:0.9227374188311688, time_count:0.004930019378662109\n",
      "================================\n",
      "epoch_14: test_acc:0.8845152243589743\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "# Lenet with BatchNormal in Linear\n",
    "# LeNet\n",
    "# input: nx1x28x28\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import load_data_fashion_mnist\n",
    "from d2l import train_ch6_gpu\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2),nn.BatchNorm2d(6),nn.Sigmoid(),  # nx6x28x28\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),  # nx6x14x14\n",
    "    nn.Conv2d(6, 16, kernel_size=5),nn.BatchNorm2d(16),nn.Sigmoid(),  # nx16x10x10\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),  # nx16x5x5\n",
    "    nn.Flatten(),  # nx400\n",
    "    #  full connection block\n",
    "    nn.Linear(16 * 5 * 5, 120),nn.BatchNorm1d(120) ,nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.BatchNorm1d(84),nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")\n",
    "\n",
    "X = torch.rand((256,1,28,28),dtype=torch.float32)\n",
    "\n",
    "net(X)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t\\t',X.shape)\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "\n",
    "lr, num_epochs = 1, 15\n",
    "train_ch6_gpu(net,train_iter=train_iter,test_iter=test_iter,num_epochs=num_epochs,lr=lr,device='cuda:0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}